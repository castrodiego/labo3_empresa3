{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "946a34f4-5c14-46cf-a39d-9794031463bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import winsound\n",
    "import datetime\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ac74ea-68b7-46f2-83ba-a06c00f1e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "############# Setear segun cada maquina ############\n",
    "#os.chdir(\"C:/Users/herna/labo3_empresa3_repo/datasets\")\n",
    "os.chdir(\"C:/diego_tools/labo3/dataset\")\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02238d29-8545-4363-b04a-f73d55495d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_sellout_train = \"emp3_sellout_product_train.csv\"\n",
    "arch_min_max_prod = \"emp3_min_max_prod.csv\"\n",
    "arch_mean_std_prod = \"emp3_mean_std_prod.csv\"\n",
    "arch_prod_ids_prediccion = \"productos_a_predecir.csv\"\n",
    "arch_predicciones_full = \"emp3_lightgbm_prediccion_full.csv\"\n",
    "arch_predicciones_simple = \"emp3_lightgbm_prediccion.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ab683a-6cae-484a-9f93-b25e2b2909e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipos_transf = ['sin_transformacion', 'normalizacion', 'estandarizacion']\n",
    "GLOBAL_TRANSF = tipos_transf[0]\n",
    "iteraciones_random_search = 50\n",
    "\n",
    "\n",
    "GLOBAL_PRODUCT_IDS = pd.DataFrame() #aca solamente se define, se setea mas abajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d24bb06-b54d-488d-9554-fbcb581dc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marco en train, holdout y descartar para considerarlo en las transformaciones\n",
    "periodo_inicio=201701 #inclusive\n",
    "train_periodo_limite = 201810 #inclusive\n",
    "validate_periodo = 201812\n",
    "train_all_periodo_limite = 201812 #inclusive\n",
    "holdout_periodo = 201902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a58411-d6ca-4191-9ca1-7a7bc6ce103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### NORMALIZACION\n",
    "def normalizar_valor(valor,minimo,maximo):\n",
    "    if np.isnan(minimo):\n",
    "        return valor #si no hay minimo, devuelvo valor original (no tener minimo significa que no habia datos en train)\n",
    "    else:\n",
    "        if (maximo-minimo)==0: \n",
    "            return 0\n",
    "        else:\n",
    "            return (valor - minimo) / (maximo-minimo)\n",
    "\n",
    "        \n",
    "def desnormalizar_valor(valor,minimo,maximo):\n",
    "    if np.isnan(minimo):\n",
    "        return valor #si no hay minimo, devuelvo valor original (no tener minimo significa que no habia datos en train)\n",
    "    else:\n",
    "        return (valor * (maximo-minimo)) + minimo\n",
    "\n",
    "def normalizar_tn(df_param):\n",
    "    #Calculo min max solamente sobre train (para evitar data leakage)\n",
    "    df_train = df_param[(df_param.periodo<=train_periodo_limite) & (df_param.periodo >= periodo_inicio)]\n",
    "    df_train = df_train[[\"product_id\",\"tn\"]]\n",
    "    \n",
    "    #Calculo min max por producto y lo guardo para poder revertir posteriormente\n",
    "    df_min_max_prod = df_train.groupby('product_id')['tn'].agg(['max', 'min']).reset_index()\n",
    "    df_min_max_prod = df_min_max_prod.rename(columns={\"min\":\"valor_1\",\"max\":\"valor_2\"})\n",
    "    df_min_max_prod.to_csv(arch_min_max_prod, index=False)\n",
    "        \n",
    "    df_ret = df_param.merge(df_min_max_prod,how=\"left\",on=\"product_id\") #puede haber productos que no aparezcan, por eso left\n",
    "    \n",
    "    # Selecciono columnas a normalizar\n",
    "    \n",
    "    # Me guardo la original para comparar\n",
    "    df_ret[\"tn_original\"]=df_ret.tn\n",
    "    \n",
    "    # Dropeo algunas (para evitar ruido)\n",
    "    cols_remover = [\"cust_request_tn\",\"dif_cust_request_tn\",\"cust_request_qty\"]\n",
    "    cols_remover.extend([col for col in df_ret.columns if \"cat1_\" in col])\n",
    "    cols_remover.extend([col for col in df_ret.columns if \"cat2_\" in col])\n",
    "    cols_remover.extend([col for col in df_ret.columns if \"cat3_\" in col])\n",
    "        \n",
    "    df_ret = df_ret.drop(columns=cols_remover)  \n",
    "    \n",
    "    # Normalizo tn, lags y deltas\n",
    "    lag_cols = [col for col in df_ret.columns if \"lag\" in col]\n",
    "    delta_cols = [col for col in df_ret.columns if \"delta\" in col]\n",
    "    cols_norm = [\"tn\",\"tn_mas_2\"]\n",
    "    cols_norm.extend(lag_cols)\n",
    "    cols_norm.extend(delta_cols)\n",
    "                    \n",
    "    for col_norm in cols_norm:\n",
    "        df_ret[col_norm] =df_ret.apply(lambda row: normalizar_valor(row[col_norm],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "    \n",
    "    return df_ret\n",
    "\n",
    "############# ESTANDARIZACION\n",
    "def estandarizar_valor(valor,media,desvio):\n",
    "    if np.isnan(media):\n",
    "        return valor #si no hay media, devuelvo valor original (no tener media significa que no habia datos en train)\n",
    "    else:\n",
    "        if desvio==0: \n",
    "            return 0\n",
    "        else:\n",
    "            return (valor - media) / desvio\n",
    "\n",
    "def desestandarizar_valor(valor,media,desvio):\n",
    "    if np.isnan(media):\n",
    "        return valor #si no hay media, devuelvo valor original (no tener media significa que no habia datos en train)\n",
    "    else:\n",
    "        return (valor * desvio) + media\n",
    "    \n",
    "def estandarizar_tn(df_param):\n",
    "    #Calculo min max solamente sobre train (para evitar data leakage)\n",
    "    df_train = df_param[(df_param.periodo<=train_periodo_limite) & (df_param.periodo >= periodo_inicio)]\n",
    "    df_train = df_train[[\"product_id\",\"tn\"]]\n",
    "    \n",
    "    #Calculo media y desvio por producto y lo guardo para poder revertir posteriormente\n",
    "    df_mean_std_prod = df_train.groupby('product_id')['tn'].agg(['mean', lambda x: np.std(x,ddof=0)]).reset_index() #se usa ddof=0 para evitar NaN cuando hay un solo producto\n",
    "    df_mean_std_prod.columns = [\"product_id\",'valor_1', 'valor_2']\n",
    "    df_mean_std_prod.to_csv(arch_mean_std_prod, index=False)\n",
    "        \n",
    "    df_ret = df_param.merge(df_mean_std_prod,how=\"left\",on=\"product_id\")\n",
    "    \n",
    "    # Selecciono columnas a estandarizar\n",
    "    \n",
    "    # Me guardo la original para comparar\n",
    "    df_ret[\"tn_original\"]=df_ret.tn\n",
    "    \n",
    "    # Dropeo algunas (para evitar ruido)\n",
    "    cols_remover = [\"cust_request_tn\",\"dif_cust_request_tn\",\"cust_request_qty\"]\n",
    "    cols_remover.extend([col for col in df_ret.columns if \"cat1_\" in col])\n",
    "    cols_remover.extend([col for col in df_ret.columns if \"cat2_\" in col])\n",
    "    cols_remover.extend([col for col in df_ret.columns if \"cat3_\" in col])\n",
    "        \n",
    "    df_ret = df_ret.drop(columns=cols_remover)  \n",
    "    \n",
    "    # Estandarizo tn, lags y deltas\n",
    "    lag_cols = [col for col in df_ret.columns if \"lag\" in col]\n",
    "    delta_cols = [col for col in df_ret.columns if \"delta\" in col]\n",
    "    cols_norm = [\"tn\",\"tn_mas_2\"]\n",
    "    cols_norm.extend(lag_cols)\n",
    "    cols_norm.extend(delta_cols)\n",
    "                    \n",
    "    for col_norm in cols_norm:\n",
    "        df_ret[col_norm] =df_ret.apply(lambda row: estandarizar_valor(row[col_norm],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "    \n",
    "    return df_ret\n",
    "\n",
    "################### TRANSFORMACION    \n",
    "def transformar_valor(valor,var1,var2):\n",
    "    if GLOBAL_TRANSF==\"normalizacion\":\n",
    "        return normalizar_valor(valor,var1,var2)\n",
    "    elif GLOBAL_TRANSF==\"estandarizacion\":\n",
    "        return estandarizar_valor(valor,var1,var2)\n",
    "    else:\n",
    "        return valor\n",
    "\n",
    "def destransformar_valor(valor,var1,var2):\n",
    "    if GLOBAL_TRANSF==\"normalizacion\":\n",
    "        return desnormalizar_valor(valor,var1,var2)\n",
    "    elif GLOBAL_TRANSF==\"estandarizacion\":\n",
    "        return desestandarizar_valor(valor,var1,var2)\n",
    "    else:\n",
    "        return valor\n",
    "\n",
    "def graficar_ejemplo_transformacion(df_param):\n",
    "    df_param = df_param[df_param.product_id==20001]\n",
    "    \n",
    "    plt.plot(df_param.tn_original)\n",
    "    plt.title(\"Original\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(df_param.tn)\n",
    "    plt.title(\"Transformado\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ec34c5-543c-45d7-b3a9-4033642029e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ DEFINO Vector Global de Productos #################\n",
    "def actualizar_global_prods(y_vector):\n",
    "    # Ademas del id y los valores para \"destransformar\", se deja el tn original porque la destransformacion puede no ser\n",
    "    # precisa para productos que no estaban en train\n",
    "    GLOBAL_PRODUCT_IDS = pd.DataFrame(data={\"product_id\":X_holdout.product_id, \"tn_orig\":np.array(y_vector)})\n",
    "    GLOBAL_PRODUCT_IDS = GLOBAL_PRODUCT_IDS.merge(df_prod_val1_val2,how=\"left\",on=\"product_id\")\n",
    "    GLOBAL_PRODUCT_IDS = GLOBAL_PRODUCT_IDS.sort_values(by=\"product_id\",ascending=True)\n",
    "    \n",
    "    return GLOBAL_PRODUCT_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "547b30c6-7d6b-4c08-872b-6a88a987b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(y, y_pred):\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    #Solamente destransformo la prediccion (para el y tomo el original de la columna tn_orig)\n",
    "    df_calculo = GLOBAL_PRODUCT_IDS.copy()\n",
    "    df_calculo[\"y_pred\"] = y_pred\n",
    "    df_calculo[\"y_pred_destransformado\"]=df_calculo.apply(lambda row: destransformar_valor(row[\"y_pred\"],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "\n",
    "    y = df_calculo.tn_orig\n",
    "    y_pred = df_calculo.y_pred_destransformado\n",
    "    \n",
    "    #Las predicciones negativas se convierten a 0\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    \n",
    "    dif_abs = sum(abs(y - y_pred))\n",
    "    suma_real = sum(y)\n",
    "    return round(100*dif_abs/suma_real,2)\n",
    "\n",
    "def lgbm_error_rate(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    ret_val = error_rate(labels,preds)\n",
    "    return 'ER', ret_val, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd18870-d967-4531-93c6-c6d3be773b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def destransformar_vector(y_vector):\n",
    "    df_calculo = GLOBAL_PRODUCT_IDS.copy()\n",
    "    df_calculo[\"y\"] = y_vector\n",
    "    df_calculo[\"y_destransformado\"]=df_calculo.apply(lambda row: destransformar_valor(row[\"y\"],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "\n",
    "    return df_calculo.y_destransformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8934c106-c110-4264-9b51-aca4daf277e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lgb_importances(model, plot=False, num=10):\n",
    "    gain = model.feature_importance('gain')\n",
    "    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n",
    "                             'split': model.feature_importance('split'),\n",
    "                             'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.set(font_scale=1)\n",
    "        sns.barplot(x=\"gain\", y=\"feature\", data=feat_imp[0:25])\n",
    "        plt.title('feature')\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=True)\n",
    "    else:\n",
    "        print(feat_imp.head(num))\n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ccdb1f-2f93-4bb9-9f57-9bdf50c4251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ebccf1f-0747-4c1b-ae14-f03f7943be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sellout = pd.read_csv(arch_sellout_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "524a6a9f-0815-40db-ad8d-bfaf483304ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>imputado</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>periodo_fecha</th>\n",
       "      <th>mes</th>\n",
       "      <th>meses_historia</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>producto_estrella</th>\n",
       "      <th>temp_media</th>\n",
       "      <th>temp_max_media</th>\n",
       "      <th>temp_min_media</th>\n",
       "      <th>IPC</th>\n",
       "      <th>promedio_mens_dolar_venta</th>\n",
       "      <th>catastrofe</th>\n",
       "      <th>dif_cust_request_tn</th>\n",
       "      <th>dif_cust_request_tn_porc</th>\n",
       "      <th>tn_lag_1</th>\n",
       "      <th>tn_lag_2</th>\n",
       "      <th>tn_lag_3</th>\n",
       "      <th>tn_lag_4</th>\n",
       "      <th>tn_lag_5</th>\n",
       "      <th>tn_lag_6</th>\n",
       "      <th>tn_lag_7</th>\n",
       "      <th>tn_lag_8</th>\n",
       "      <th>tn_lag_9</th>\n",
       "      <th>tn_lag_10</th>\n",
       "      <th>tn_lag_11</th>\n",
       "      <th>tn_lag_12</th>\n",
       "      <th>tn_lag_13</th>\n",
       "      <th>tn_lag_14</th>\n",
       "      <th>tn_lag_15</th>\n",
       "      <th>tn_mas_2</th>\n",
       "      <th>tn_delta_1</th>\n",
       "      <th>tn_delta_2</th>\n",
       "      <th>tn_delta_3</th>\n",
       "      <th>tn_delta_4</th>\n",
       "      <th>tn_delta_5</th>\n",
       "      <th>tn_delta_6</th>\n",
       "      <th>tn_delta_7</th>\n",
       "      <th>tn_delta_8</th>\n",
       "      <th>tn_delta_9</th>\n",
       "      <th>tn_delta_10</th>\n",
       "      <th>tn_delta_11</th>\n",
       "      <th>tn_delta_12</th>\n",
       "      <th>tn_delta_13</th>\n",
       "      <th>tn_delta_14</th>\n",
       "      <th>tn_delta_15</th>\n",
       "      <th>cat1_tn</th>\n",
       "      <th>cat1_tn_lag_1</th>\n",
       "      <th>cat1_tn_delta_1</th>\n",
       "      <th>cat1_tn_lag_2</th>\n",
       "      <th>cat1_tn_delta_2</th>\n",
       "      <th>cat1_tn_lag_3</th>\n",
       "      <th>cat1_tn_delta_3</th>\n",
       "      <th>cat1_tn_lag_4</th>\n",
       "      <th>cat1_tn_delta_4</th>\n",
       "      <th>cat1_tn_lag_5</th>\n",
       "      <th>cat1_tn_delta_5</th>\n",
       "      <th>cat1_tn_lag_6</th>\n",
       "      <th>cat1_tn_delta_6</th>\n",
       "      <th>cat1_tn_lag_7</th>\n",
       "      <th>cat1_tn_delta_7</th>\n",
       "      <th>cat1_tn_lag_8</th>\n",
       "      <th>cat1_tn_delta_8</th>\n",
       "      <th>cat1_tn_lag_9</th>\n",
       "      <th>cat1_tn_delta_9</th>\n",
       "      <th>cat1_tn_lag_10</th>\n",
       "      <th>cat1_tn_delta_10</th>\n",
       "      <th>cat1_tn_lag_11</th>\n",
       "      <th>cat1_tn_delta_11</th>\n",
       "      <th>cat1_tn_lag_12</th>\n",
       "      <th>cat1_tn_delta_12</th>\n",
       "      <th>cat1_tn_lag_13</th>\n",
       "      <th>cat1_tn_delta_13</th>\n",
       "      <th>cat1_tn_lag_14</th>\n",
       "      <th>cat1_tn_delta_14</th>\n",
       "      <th>cat1_tn_lag_15</th>\n",
       "      <th>cat1_tn_delta_15</th>\n",
       "      <th>cat2_tn</th>\n",
       "      <th>cat2_tn_lag_1</th>\n",
       "      <th>cat2_tn_delta_1</th>\n",
       "      <th>cat2_tn_lag_2</th>\n",
       "      <th>cat2_tn_delta_2</th>\n",
       "      <th>cat2_tn_lag_3</th>\n",
       "      <th>cat2_tn_delta_3</th>\n",
       "      <th>cat2_tn_lag_4</th>\n",
       "      <th>cat2_tn_delta_4</th>\n",
       "      <th>cat2_tn_lag_5</th>\n",
       "      <th>cat2_tn_delta_5</th>\n",
       "      <th>cat2_tn_lag_6</th>\n",
       "      <th>cat2_tn_delta_6</th>\n",
       "      <th>cat2_tn_lag_7</th>\n",
       "      <th>cat2_tn_delta_7</th>\n",
       "      <th>cat2_tn_lag_8</th>\n",
       "      <th>cat2_tn_delta_8</th>\n",
       "      <th>cat2_tn_lag_9</th>\n",
       "      <th>cat2_tn_delta_9</th>\n",
       "      <th>cat2_tn_lag_10</th>\n",
       "      <th>cat2_tn_delta_10</th>\n",
       "      <th>cat2_tn_lag_11</th>\n",
       "      <th>cat2_tn_delta_11</th>\n",
       "      <th>cat2_tn_lag_12</th>\n",
       "      <th>cat2_tn_delta_12</th>\n",
       "      <th>cat2_tn_lag_13</th>\n",
       "      <th>cat2_tn_delta_13</th>\n",
       "      <th>cat2_tn_lag_14</th>\n",
       "      <th>cat2_tn_delta_14</th>\n",
       "      <th>cat2_tn_lag_15</th>\n",
       "      <th>cat2_tn_delta_15</th>\n",
       "      <th>cat3_tn</th>\n",
       "      <th>cat3_tn_lag_1</th>\n",
       "      <th>cat3_tn_delta_1</th>\n",
       "      <th>cat3_tn_lag_2</th>\n",
       "      <th>cat3_tn_delta_2</th>\n",
       "      <th>cat3_tn_lag_3</th>\n",
       "      <th>cat3_tn_delta_3</th>\n",
       "      <th>cat3_tn_lag_4</th>\n",
       "      <th>cat3_tn_delta_4</th>\n",
       "      <th>cat3_tn_lag_5</th>\n",
       "      <th>cat3_tn_delta_5</th>\n",
       "      <th>cat3_tn_lag_6</th>\n",
       "      <th>cat3_tn_delta_6</th>\n",
       "      <th>cat3_tn_lag_7</th>\n",
       "      <th>cat3_tn_delta_7</th>\n",
       "      <th>cat3_tn_lag_8</th>\n",
       "      <th>cat3_tn_delta_8</th>\n",
       "      <th>cat3_tn_lag_9</th>\n",
       "      <th>cat3_tn_delta_9</th>\n",
       "      <th>cat3_tn_lag_10</th>\n",
       "      <th>cat3_tn_delta_10</th>\n",
       "      <th>cat3_tn_lag_11</th>\n",
       "      <th>cat3_tn_delta_11</th>\n",
       "      <th>cat3_tn_lag_12</th>\n",
       "      <th>cat3_tn_delta_12</th>\n",
       "      <th>cat3_tn_lag_13</th>\n",
       "      <th>cat3_tn_delta_13</th>\n",
       "      <th>cat3_tn_lag_14</th>\n",
       "      <th>cat3_tn_delta_14</th>\n",
       "      <th>cat3_tn_lag_15</th>\n",
       "      <th>cat3_tn_delta_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>934.77</td>\n",
       "      <td>937.73</td>\n",
       "      <td>479.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1303.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>550.16</td>\n",
       "      <td>555.19</td>\n",
       "      <td>391.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>LIMPIEX</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>834.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20009</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>378.08</td>\n",
       "      <td>380.53</td>\n",
       "      <td>429.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ROPEX1</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20015</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>304.25</td>\n",
       "      <td>307.99</td>\n",
       "      <td>374.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ROPEX1</td>\n",
       "      <td>800.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20026</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>184.40</td>\n",
       "      <td>185.11</td>\n",
       "      <td>307.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>LIMPIEX</td>\n",
       "      <td>800.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  periodo  imputado     tn  cust_request_tn  cust_request_qty  \\\n",
       "0       20001   201701         0 934.77           937.73            479.00   \n",
       "1       20002   201701         0 550.16           555.19            391.00   \n",
       "2       20009   201701         0 378.08           380.53            429.00   \n",
       "3       20015   201701         0 304.25           307.99            374.00   \n",
       "4       20026   201701         0 184.40           185.11            307.00   \n",
       "\n",
       "   plan_precios_cuidados periodo_fecha  mes  meses_historia cat1         cat2  \\\n",
       "0                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "1                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "2                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "3                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "4                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "\n",
       "      cat3    brand  sku_size  producto_estrella  temp_media  temp_max_media  \\\n",
       "0  Liquido    ARIEL   3000.00               1.00       25.65           30.40   \n",
       "1  Liquido  LIMPIEX   3000.00               1.00       25.65           30.40   \n",
       "2  Liquido   ROPEX1   3000.00               1.00       25.65           30.40   \n",
       "3  Liquido   ROPEX1    800.00               0.00       25.65           30.40   \n",
       "4  Liquido  LIMPIEX    800.00               0.00       25.65           30.40   \n",
       "\n",
       "   temp_min_media  IPC  promedio_mens_dolar_venta  catastrofe  \\\n",
       "0           20.90 1.60                      15.91       False   \n",
       "1           20.90 1.60                      15.91       False   \n",
       "2           20.90 1.60                      15.91       False   \n",
       "3           20.90 1.60                      15.91       False   \n",
       "4           20.90 1.60                      15.91       False   \n",
       "\n",
       "   dif_cust_request_tn  dif_cust_request_tn_porc  tn_lag_1  tn_lag_2  \\\n",
       "0                 2.95                      0.32       NaN       NaN   \n",
       "1                 5.03                      0.91       NaN       NaN   \n",
       "2                 2.45                      0.64       NaN       NaN   \n",
       "3                 3.74                      1.22       NaN       NaN   \n",
       "4                 0.71                      0.38       NaN       NaN   \n",
       "\n",
       "   tn_lag_3  tn_lag_4  tn_lag_5  tn_lag_6  tn_lag_7  tn_lag_8  tn_lag_9  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   tn_lag_10  tn_lag_11  tn_lag_12  tn_lag_13  tn_lag_14  tn_lag_15  tn_mas_2  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   1303.36   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN    834.74   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN    456.07   \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN    462.48   \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN    259.71   \n",
       "\n",
       "   tn_delta_1  tn_delta_2  tn_delta_3  tn_delta_4  tn_delta_5  tn_delta_6  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   tn_delta_7  tn_delta_8  tn_delta_9  tn_delta_10  tn_delta_11  tn_delta_12  \\\n",
       "0         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "1         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "2         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "3         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "4         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "   tn_delta_13  tn_delta_14  tn_delta_15  cat1_tn  cat1_tn_lag_1  \\\n",
       "0          NaN          NaN          NaN 20304.29            NaN   \n",
       "1          NaN          NaN          NaN 20304.29            NaN   \n",
       "2          NaN          NaN          NaN 20304.29            NaN   \n",
       "3          NaN          NaN          NaN 20304.29            NaN   \n",
       "4          NaN          NaN          NaN 20304.29            NaN   \n",
       "\n",
       "   cat1_tn_delta_1  cat1_tn_lag_2  cat1_tn_delta_2  cat1_tn_lag_3  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_3  cat1_tn_lag_4  cat1_tn_delta_4  cat1_tn_lag_5  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_5  cat1_tn_lag_6  cat1_tn_delta_6  cat1_tn_lag_7  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_7  cat1_tn_lag_8  cat1_tn_delta_8  cat1_tn_lag_9  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_9  cat1_tn_lag_10  cat1_tn_delta_10  cat1_tn_lag_11  \\\n",
       "0              NaN             NaN               NaN             NaN   \n",
       "1              NaN             NaN               NaN             NaN   \n",
       "2              NaN             NaN               NaN             NaN   \n",
       "3              NaN             NaN               NaN             NaN   \n",
       "4              NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat1_tn_delta_11  cat1_tn_lag_12  cat1_tn_delta_12  cat1_tn_lag_13  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat1_tn_delta_13  cat1_tn_lag_14  cat1_tn_delta_14  cat1_tn_lag_15  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat1_tn_delta_15  cat2_tn  cat2_tn_lag_1  cat2_tn_delta_1  cat2_tn_lag_2  \\\n",
       "0               NaN 11153.30            NaN              NaN            NaN   \n",
       "1               NaN 11153.30            NaN              NaN            NaN   \n",
       "2               NaN 11153.30            NaN              NaN            NaN   \n",
       "3               NaN 11153.30            NaN              NaN            NaN   \n",
       "4               NaN 11153.30            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_2  cat2_tn_lag_3  cat2_tn_delta_3  cat2_tn_lag_4  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_4  cat2_tn_lag_5  cat2_tn_delta_5  cat2_tn_lag_6  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_6  cat2_tn_lag_7  cat2_tn_delta_7  cat2_tn_lag_8  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_8  cat2_tn_lag_9  cat2_tn_delta_9  cat2_tn_lag_10  \\\n",
       "0              NaN            NaN              NaN             NaN   \n",
       "1              NaN            NaN              NaN             NaN   \n",
       "2              NaN            NaN              NaN             NaN   \n",
       "3              NaN            NaN              NaN             NaN   \n",
       "4              NaN            NaN              NaN             NaN   \n",
       "\n",
       "   cat2_tn_delta_10  cat2_tn_lag_11  cat2_tn_delta_11  cat2_tn_lag_12  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat2_tn_delta_12  cat2_tn_lag_13  cat2_tn_delta_13  cat2_tn_lag_14  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat2_tn_delta_14  cat2_tn_lag_15  cat2_tn_delta_15  cat3_tn  cat3_tn_lag_1  \\\n",
       "0               NaN             NaN               NaN  3871.39            NaN   \n",
       "1               NaN             NaN               NaN  3871.39            NaN   \n",
       "2               NaN             NaN               NaN  3871.39            NaN   \n",
       "3               NaN             NaN               NaN  3871.39            NaN   \n",
       "4               NaN             NaN               NaN  3871.39            NaN   \n",
       "\n",
       "   cat3_tn_delta_1  cat3_tn_lag_2  cat3_tn_delta_2  cat3_tn_lag_3  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_3  cat3_tn_lag_4  cat3_tn_delta_4  cat3_tn_lag_5  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_5  cat3_tn_lag_6  cat3_tn_delta_6  cat3_tn_lag_7  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_7  cat3_tn_lag_8  cat3_tn_delta_8  cat3_tn_lag_9  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_9  cat3_tn_lag_10  cat3_tn_delta_10  cat3_tn_lag_11  \\\n",
       "0              NaN             NaN               NaN             NaN   \n",
       "1              NaN             NaN               NaN             NaN   \n",
       "2              NaN             NaN               NaN             NaN   \n",
       "3              NaN             NaN               NaN             NaN   \n",
       "4              NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat3_tn_delta_11  cat3_tn_lag_12  cat3_tn_delta_12  cat3_tn_lag_13  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat3_tn_delta_13  cat3_tn_lag_14  cat3_tn_delta_14  cat3_tn_lag_15  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat3_tn_delta_15  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sellout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a5faa9-cdd0-4019-bb86-8cc0098b7cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23173 entries, 0 to 23172\n",
      "Columns: 148 entries, product_id to cat3_tn_delta_15\n",
      "dtypes: bool(1), float64(137), int64(5), object(5)\n",
      "memory usage: 26.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sellout.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "748b87e1-5f79-4bfa-9195-badccc6fe589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id              0\n",
       "periodo                 0\n",
       "imputado                0\n",
       "tn                      0\n",
       "cust_request_tn         0\n",
       "                    ...  \n",
       "cat3_tn_delta_13    11508\n",
       "cat3_tn_lag_14      12456\n",
       "cat3_tn_delta_14    12456\n",
       "cat3_tn_lag_15      13397\n",
       "cat3_tn_delta_15    13397\n",
       "Length: 148, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sellout.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a385bb4-11fa-4fef-ac8d-1980c2cc70cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id\n",
       "0       20480\n",
       "1       20481\n",
       "2       20482\n",
       "3       20483\n",
       "4       20484"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prods_prediccion=pd.read_csv(arch_prod_ids_prediccion)\n",
    "df_prods_prediccion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0192f673-6ff3-4fdc-9264-be0942d1778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 868 entries, 0 to 867\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   product_id  868 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 6.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_prods_prediccion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da55ec8b-adac-40e2-9ddf-5890f20ba5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868\n",
      "868\n"
     ]
    }
   ],
   "source": [
    "# Antes de transformar, se guardan los y_validate y holdout originales (se van a usar en el vector global)\n",
    "# Esto se debe a que la \"destransformacion\" no siempre es perfecta, considerando productos que no estuvieron en train\n",
    "df_sellout_validate_orig = df_sellout[(df_sellout.product_id.isin(df_prods_prediccion.product_id)) & (df_sellout.periodo==validate_periodo)]\n",
    "df_sellout_validate_orig = df_sellout_validate_orig.sort_values(by=\"product_id\",ascending=True)\n",
    "y_validate_orig = df_sellout_validate_orig.tn_mas_2\n",
    "print(len(y_validate_orig))\n",
    "\n",
    "df_sellout_holdout_orig = df_sellout[(df_sellout.product_id.isin(df_prods_prediccion.product_id)) & (df_sellout.periodo==holdout_periodo)]\n",
    "df_sellout_holdout_orig = df_sellout_holdout_orig.sort_values(by=\"product_id\",ascending=True)\n",
    "y_holdout_orig = df_sellout_holdout_orig.tn_mas_2\n",
    "print(len(y_holdout_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6cb1d1-ee99-4471-a8d9-86ec9c4967a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sin Transformacion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>imputado</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>periodo_fecha</th>\n",
       "      <th>mes</th>\n",
       "      <th>meses_historia</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>producto_estrella</th>\n",
       "      <th>temp_media</th>\n",
       "      <th>temp_max_media</th>\n",
       "      <th>temp_min_media</th>\n",
       "      <th>IPC</th>\n",
       "      <th>promedio_mens_dolar_venta</th>\n",
       "      <th>catastrofe</th>\n",
       "      <th>dif_cust_request_tn</th>\n",
       "      <th>dif_cust_request_tn_porc</th>\n",
       "      <th>tn_lag_1</th>\n",
       "      <th>tn_lag_2</th>\n",
       "      <th>tn_lag_3</th>\n",
       "      <th>tn_lag_4</th>\n",
       "      <th>tn_lag_5</th>\n",
       "      <th>tn_lag_6</th>\n",
       "      <th>tn_lag_7</th>\n",
       "      <th>tn_lag_8</th>\n",
       "      <th>tn_lag_9</th>\n",
       "      <th>tn_lag_10</th>\n",
       "      <th>tn_lag_11</th>\n",
       "      <th>tn_lag_12</th>\n",
       "      <th>tn_lag_13</th>\n",
       "      <th>tn_lag_14</th>\n",
       "      <th>tn_lag_15</th>\n",
       "      <th>tn_mas_2</th>\n",
       "      <th>tn_delta_1</th>\n",
       "      <th>tn_delta_2</th>\n",
       "      <th>tn_delta_3</th>\n",
       "      <th>tn_delta_4</th>\n",
       "      <th>tn_delta_5</th>\n",
       "      <th>tn_delta_6</th>\n",
       "      <th>tn_delta_7</th>\n",
       "      <th>tn_delta_8</th>\n",
       "      <th>tn_delta_9</th>\n",
       "      <th>tn_delta_10</th>\n",
       "      <th>tn_delta_11</th>\n",
       "      <th>tn_delta_12</th>\n",
       "      <th>tn_delta_13</th>\n",
       "      <th>tn_delta_14</th>\n",
       "      <th>tn_delta_15</th>\n",
       "      <th>cat1_tn</th>\n",
       "      <th>cat1_tn_lag_1</th>\n",
       "      <th>cat1_tn_delta_1</th>\n",
       "      <th>cat1_tn_lag_2</th>\n",
       "      <th>cat1_tn_delta_2</th>\n",
       "      <th>cat1_tn_lag_3</th>\n",
       "      <th>cat1_tn_delta_3</th>\n",
       "      <th>cat1_tn_lag_4</th>\n",
       "      <th>cat1_tn_delta_4</th>\n",
       "      <th>cat1_tn_lag_5</th>\n",
       "      <th>cat1_tn_delta_5</th>\n",
       "      <th>cat1_tn_lag_6</th>\n",
       "      <th>cat1_tn_delta_6</th>\n",
       "      <th>cat1_tn_lag_7</th>\n",
       "      <th>cat1_tn_delta_7</th>\n",
       "      <th>cat1_tn_lag_8</th>\n",
       "      <th>cat1_tn_delta_8</th>\n",
       "      <th>cat1_tn_lag_9</th>\n",
       "      <th>cat1_tn_delta_9</th>\n",
       "      <th>cat1_tn_lag_10</th>\n",
       "      <th>cat1_tn_delta_10</th>\n",
       "      <th>cat1_tn_lag_11</th>\n",
       "      <th>cat1_tn_delta_11</th>\n",
       "      <th>cat1_tn_lag_12</th>\n",
       "      <th>cat1_tn_delta_12</th>\n",
       "      <th>cat1_tn_lag_13</th>\n",
       "      <th>cat1_tn_delta_13</th>\n",
       "      <th>cat1_tn_lag_14</th>\n",
       "      <th>cat1_tn_delta_14</th>\n",
       "      <th>cat1_tn_lag_15</th>\n",
       "      <th>cat1_tn_delta_15</th>\n",
       "      <th>cat2_tn</th>\n",
       "      <th>cat2_tn_lag_1</th>\n",
       "      <th>cat2_tn_delta_1</th>\n",
       "      <th>cat2_tn_lag_2</th>\n",
       "      <th>cat2_tn_delta_2</th>\n",
       "      <th>cat2_tn_lag_3</th>\n",
       "      <th>cat2_tn_delta_3</th>\n",
       "      <th>cat2_tn_lag_4</th>\n",
       "      <th>cat2_tn_delta_4</th>\n",
       "      <th>cat2_tn_lag_5</th>\n",
       "      <th>cat2_tn_delta_5</th>\n",
       "      <th>cat2_tn_lag_6</th>\n",
       "      <th>cat2_tn_delta_6</th>\n",
       "      <th>cat2_tn_lag_7</th>\n",
       "      <th>cat2_tn_delta_7</th>\n",
       "      <th>cat2_tn_lag_8</th>\n",
       "      <th>cat2_tn_delta_8</th>\n",
       "      <th>cat2_tn_lag_9</th>\n",
       "      <th>cat2_tn_delta_9</th>\n",
       "      <th>cat2_tn_lag_10</th>\n",
       "      <th>cat2_tn_delta_10</th>\n",
       "      <th>cat2_tn_lag_11</th>\n",
       "      <th>cat2_tn_delta_11</th>\n",
       "      <th>cat2_tn_lag_12</th>\n",
       "      <th>cat2_tn_delta_12</th>\n",
       "      <th>cat2_tn_lag_13</th>\n",
       "      <th>cat2_tn_delta_13</th>\n",
       "      <th>cat2_tn_lag_14</th>\n",
       "      <th>cat2_tn_delta_14</th>\n",
       "      <th>cat2_tn_lag_15</th>\n",
       "      <th>cat2_tn_delta_15</th>\n",
       "      <th>cat3_tn</th>\n",
       "      <th>cat3_tn_lag_1</th>\n",
       "      <th>cat3_tn_delta_1</th>\n",
       "      <th>cat3_tn_lag_2</th>\n",
       "      <th>cat3_tn_delta_2</th>\n",
       "      <th>cat3_tn_lag_3</th>\n",
       "      <th>cat3_tn_delta_3</th>\n",
       "      <th>cat3_tn_lag_4</th>\n",
       "      <th>cat3_tn_delta_4</th>\n",
       "      <th>cat3_tn_lag_5</th>\n",
       "      <th>cat3_tn_delta_5</th>\n",
       "      <th>cat3_tn_lag_6</th>\n",
       "      <th>cat3_tn_delta_6</th>\n",
       "      <th>cat3_tn_lag_7</th>\n",
       "      <th>cat3_tn_delta_7</th>\n",
       "      <th>cat3_tn_lag_8</th>\n",
       "      <th>cat3_tn_delta_8</th>\n",
       "      <th>cat3_tn_lag_9</th>\n",
       "      <th>cat3_tn_delta_9</th>\n",
       "      <th>cat3_tn_lag_10</th>\n",
       "      <th>cat3_tn_delta_10</th>\n",
       "      <th>cat3_tn_lag_11</th>\n",
       "      <th>cat3_tn_delta_11</th>\n",
       "      <th>cat3_tn_lag_12</th>\n",
       "      <th>cat3_tn_delta_12</th>\n",
       "      <th>cat3_tn_lag_13</th>\n",
       "      <th>cat3_tn_delta_13</th>\n",
       "      <th>cat3_tn_lag_14</th>\n",
       "      <th>cat3_tn_delta_14</th>\n",
       "      <th>cat3_tn_lag_15</th>\n",
       "      <th>cat3_tn_delta_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>934.77</td>\n",
       "      <td>937.73</td>\n",
       "      <td>479.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1303.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>550.16</td>\n",
       "      <td>555.19</td>\n",
       "      <td>391.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>LIMPIEX</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>834.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20009</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>378.08</td>\n",
       "      <td>380.53</td>\n",
       "      <td>429.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ROPEX1</td>\n",
       "      <td>3000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20015</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>304.25</td>\n",
       "      <td>307.99</td>\n",
       "      <td>374.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ROPEX1</td>\n",
       "      <td>800.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20026</td>\n",
       "      <td>201701</td>\n",
       "      <td>0</td>\n",
       "      <td>184.40</td>\n",
       "      <td>185.11</td>\n",
       "      <td>307.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>LIMPIEX</td>\n",
       "      <td>800.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.65</td>\n",
       "      <td>30.40</td>\n",
       "      <td>20.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>15.91</td>\n",
       "      <td>False</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20304.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11153.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  periodo  imputado     tn  cust_request_tn  cust_request_qty  \\\n",
       "0       20001   201701         0 934.77           937.73            479.00   \n",
       "1       20002   201701         0 550.16           555.19            391.00   \n",
       "2       20009   201701         0 378.08           380.53            429.00   \n",
       "3       20015   201701         0 304.25           307.99            374.00   \n",
       "4       20026   201701         0 184.40           185.11            307.00   \n",
       "\n",
       "   plan_precios_cuidados periodo_fecha  mes  meses_historia cat1         cat2  \\\n",
       "0                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "1                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "2                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "3                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "4                   0.00    2017-01-01    1               0   HC  ROPA LAVADO   \n",
       "\n",
       "      cat3    brand  sku_size  producto_estrella  temp_media  temp_max_media  \\\n",
       "0  Liquido    ARIEL   3000.00               1.00       25.65           30.40   \n",
       "1  Liquido  LIMPIEX   3000.00               1.00       25.65           30.40   \n",
       "2  Liquido   ROPEX1   3000.00               1.00       25.65           30.40   \n",
       "3  Liquido   ROPEX1    800.00               0.00       25.65           30.40   \n",
       "4  Liquido  LIMPIEX    800.00               0.00       25.65           30.40   \n",
       "\n",
       "   temp_min_media  IPC  promedio_mens_dolar_venta  catastrofe  \\\n",
       "0           20.90 1.60                      15.91       False   \n",
       "1           20.90 1.60                      15.91       False   \n",
       "2           20.90 1.60                      15.91       False   \n",
       "3           20.90 1.60                      15.91       False   \n",
       "4           20.90 1.60                      15.91       False   \n",
       "\n",
       "   dif_cust_request_tn  dif_cust_request_tn_porc  tn_lag_1  tn_lag_2  \\\n",
       "0                 2.95                      0.32       NaN       NaN   \n",
       "1                 5.03                      0.91       NaN       NaN   \n",
       "2                 2.45                      0.64       NaN       NaN   \n",
       "3                 3.74                      1.22       NaN       NaN   \n",
       "4                 0.71                      0.38       NaN       NaN   \n",
       "\n",
       "   tn_lag_3  tn_lag_4  tn_lag_5  tn_lag_6  tn_lag_7  tn_lag_8  tn_lag_9  \\\n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "   tn_lag_10  tn_lag_11  tn_lag_12  tn_lag_13  tn_lag_14  tn_lag_15  tn_mas_2  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN   1303.36   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN    834.74   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN    456.07   \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN    462.48   \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN    259.71   \n",
       "\n",
       "   tn_delta_1  tn_delta_2  tn_delta_3  tn_delta_4  tn_delta_5  tn_delta_6  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   tn_delta_7  tn_delta_8  tn_delta_9  tn_delta_10  tn_delta_11  tn_delta_12  \\\n",
       "0         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "1         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "2         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "3         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "4         NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "   tn_delta_13  tn_delta_14  tn_delta_15  cat1_tn  cat1_tn_lag_1  \\\n",
       "0          NaN          NaN          NaN 20304.29            NaN   \n",
       "1          NaN          NaN          NaN 20304.29            NaN   \n",
       "2          NaN          NaN          NaN 20304.29            NaN   \n",
       "3          NaN          NaN          NaN 20304.29            NaN   \n",
       "4          NaN          NaN          NaN 20304.29            NaN   \n",
       "\n",
       "   cat1_tn_delta_1  cat1_tn_lag_2  cat1_tn_delta_2  cat1_tn_lag_3  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_3  cat1_tn_lag_4  cat1_tn_delta_4  cat1_tn_lag_5  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_5  cat1_tn_lag_6  cat1_tn_delta_6  cat1_tn_lag_7  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_7  cat1_tn_lag_8  cat1_tn_delta_8  cat1_tn_lag_9  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat1_tn_delta_9  cat1_tn_lag_10  cat1_tn_delta_10  cat1_tn_lag_11  \\\n",
       "0              NaN             NaN               NaN             NaN   \n",
       "1              NaN             NaN               NaN             NaN   \n",
       "2              NaN             NaN               NaN             NaN   \n",
       "3              NaN             NaN               NaN             NaN   \n",
       "4              NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat1_tn_delta_11  cat1_tn_lag_12  cat1_tn_delta_12  cat1_tn_lag_13  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat1_tn_delta_13  cat1_tn_lag_14  cat1_tn_delta_14  cat1_tn_lag_15  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat1_tn_delta_15  cat2_tn  cat2_tn_lag_1  cat2_tn_delta_1  cat2_tn_lag_2  \\\n",
       "0               NaN 11153.30            NaN              NaN            NaN   \n",
       "1               NaN 11153.30            NaN              NaN            NaN   \n",
       "2               NaN 11153.30            NaN              NaN            NaN   \n",
       "3               NaN 11153.30            NaN              NaN            NaN   \n",
       "4               NaN 11153.30            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_2  cat2_tn_lag_3  cat2_tn_delta_3  cat2_tn_lag_4  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_4  cat2_tn_lag_5  cat2_tn_delta_5  cat2_tn_lag_6  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_6  cat2_tn_lag_7  cat2_tn_delta_7  cat2_tn_lag_8  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat2_tn_delta_8  cat2_tn_lag_9  cat2_tn_delta_9  cat2_tn_lag_10  \\\n",
       "0              NaN            NaN              NaN             NaN   \n",
       "1              NaN            NaN              NaN             NaN   \n",
       "2              NaN            NaN              NaN             NaN   \n",
       "3              NaN            NaN              NaN             NaN   \n",
       "4              NaN            NaN              NaN             NaN   \n",
       "\n",
       "   cat2_tn_delta_10  cat2_tn_lag_11  cat2_tn_delta_11  cat2_tn_lag_12  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat2_tn_delta_12  cat2_tn_lag_13  cat2_tn_delta_13  cat2_tn_lag_14  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat2_tn_delta_14  cat2_tn_lag_15  cat2_tn_delta_15  cat3_tn  cat3_tn_lag_1  \\\n",
       "0               NaN             NaN               NaN  3871.39            NaN   \n",
       "1               NaN             NaN               NaN  3871.39            NaN   \n",
       "2               NaN             NaN               NaN  3871.39            NaN   \n",
       "3               NaN             NaN               NaN  3871.39            NaN   \n",
       "4               NaN             NaN               NaN  3871.39            NaN   \n",
       "\n",
       "   cat3_tn_delta_1  cat3_tn_lag_2  cat3_tn_delta_2  cat3_tn_lag_3  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_3  cat3_tn_lag_4  cat3_tn_delta_4  cat3_tn_lag_5  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_5  cat3_tn_lag_6  cat3_tn_delta_6  cat3_tn_lag_7  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_7  cat3_tn_lag_8  cat3_tn_delta_8  cat3_tn_lag_9  \\\n",
       "0              NaN            NaN              NaN            NaN   \n",
       "1              NaN            NaN              NaN            NaN   \n",
       "2              NaN            NaN              NaN            NaN   \n",
       "3              NaN            NaN              NaN            NaN   \n",
       "4              NaN            NaN              NaN            NaN   \n",
       "\n",
       "   cat3_tn_delta_9  cat3_tn_lag_10  cat3_tn_delta_10  cat3_tn_lag_11  \\\n",
       "0              NaN             NaN               NaN             NaN   \n",
       "1              NaN             NaN               NaN             NaN   \n",
       "2              NaN             NaN               NaN             NaN   \n",
       "3              NaN             NaN               NaN             NaN   \n",
       "4              NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat3_tn_delta_11  cat3_tn_lag_12  cat3_tn_delta_12  cat3_tn_lag_13  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat3_tn_delta_13  cat3_tn_lag_14  cat3_tn_delta_14  cat3_tn_lag_15  \\\n",
       "0               NaN             NaN               NaN             NaN   \n",
       "1               NaN             NaN               NaN             NaN   \n",
       "2               NaN             NaN               NaN             NaN   \n",
       "3               NaN             NaN               NaN             NaN   \n",
       "4               NaN             NaN               NaN             NaN   \n",
       "\n",
       "   cat3_tn_delta_15  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GLOBAL_TRANSF == \"sin_transformacion\":\n",
    "    print(\"Sin Transformacion\")\n",
    "    df_sellout_transf = df_sellout\n",
    "    \n",
    "    df_prod_val1_val2 = pd.DataFrame(data={\"product_id\":df_sellout.product_id.unique()})\n",
    "    df_prod_val1_val2[\"valor_1\"]=0\n",
    "    df_prod_val1_val2[\"valor_2\"]=0\n",
    "    \n",
    "elif GLOBAL_TRANSF == \"normalizacion\":\n",
    "    print(\"Normalizacion\")\n",
    "    print(len(df_sellout))\n",
    "    df_sellout_transf = normalizar_tn(df_sellout)\n",
    "    print(len(df_sellout_transf))\n",
    "\n",
    "    graficar_ejemplo_transformacion(df_sellout_transf)\n",
    "    df_sellout_transf = df_sellout_transf.drop(columns=[\"tn_original\",\"valor_1\",\"valor_2\"])\n",
    "    \n",
    "    df_prod_val1_val2 = pd.read_csv(arch_min_max_prod)\n",
    "\n",
    "elif GLOBAL_TRANSF == \"estandarizacion\":\n",
    "    print(\"Estandarizacion\")\n",
    "    df_sellout_transf = estandarizar_tn(df_sellout)\n",
    "    graficar_ejemplo_transformacion(df_sellout_transf)\n",
    "    df_sellout_transf = df_sellout_transf.drop(columns=[\"tn_original\",\"valor_1\",\"valor_2\"])\n",
    "   \n",
    "    df_prod_val1_val2 = pd.read_csv(arch_mean_std_prod)\n",
    "    \n",
    "df_sellout_transf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c5b068-dba3-4de2-9aff-a7961ba3e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn_x</th>\n",
       "      <th>tn_y</th>\n",
       "      <th>tn_mas_2_x</th>\n",
       "      <th>tn_mas_2_y</th>\n",
       "      <th>tn_lag_1_x</th>\n",
       "      <th>tn_lag_1_y</th>\n",
       "      <th>tn_delta_1_x</th>\n",
       "      <th>tn_delta_1_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>201701</td>\n",
       "      <td>934.77</td>\n",
       "      <td>934.77</td>\n",
       "      <td>1303.36</td>\n",
       "      <td>1303.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>201701</td>\n",
       "      <td>550.16</td>\n",
       "      <td>550.16</td>\n",
       "      <td>834.74</td>\n",
       "      <td>834.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20009</td>\n",
       "      <td>201701</td>\n",
       "      <td>378.08</td>\n",
       "      <td>378.08</td>\n",
       "      <td>456.07</td>\n",
       "      <td>456.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20015</td>\n",
       "      <td>201701</td>\n",
       "      <td>304.25</td>\n",
       "      <td>304.25</td>\n",
       "      <td>462.48</td>\n",
       "      <td>462.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20026</td>\n",
       "      <td>201701</td>\n",
       "      <td>184.40</td>\n",
       "      <td>184.40</td>\n",
       "      <td>259.71</td>\n",
       "      <td>259.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  periodo   tn_x   tn_y  tn_mas_2_x  tn_mas_2_y  tn_lag_1_x  \\\n",
       "0       20001   201701 934.77 934.77     1303.36     1303.36         NaN   \n",
       "1       20002   201701 550.16 550.16      834.74      834.74         NaN   \n",
       "2       20009   201701 378.08 378.08      456.07      456.07         NaN   \n",
       "3       20015   201701 304.25 304.25      462.48      462.48         NaN   \n",
       "4       20026   201701 184.40 184.40      259.71      259.71         NaN   \n",
       "\n",
       "   tn_lag_1_y  tn_delta_1_x  tn_delta_1_y  \n",
       "0         NaN           NaN           NaN  \n",
       "1         NaN           NaN           NaN  \n",
       "2         NaN           NaN           NaN  \n",
       "3         NaN           NaN           NaN  \n",
       "4         NaN           NaN           NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Se verifica transformacion\n",
    "df_test = df_sellout_transf[[\"product_id\",\"periodo\",\"tn\",\"tn_mas_2\",\"tn_lag_1\",\"tn_delta_1\"]].merge(df_prod_val1_val2,how=\"left\",on=\"product_id\")\n",
    "df_test[\"tn\"]=df_test.apply(lambda row: destransformar_valor(row[\"tn\"],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "df_test[\"tn_mas_2\"]=df_test.apply(lambda row: destransformar_valor(row[\"tn_mas_2\"],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "df_test[\"tn_lag_1\"]=df_test.apply(lambda row: destransformar_valor(row[\"tn_lag_1\"],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "df_test[\"tn_delta_1\"]=df_test.apply(lambda row: destransformar_valor(row[\"tn_delta_1\"],row[\"valor_1\"],row[\"valor_2\"]),axis=1)\n",
    "df_test = df_test.merge(df_sellout[[\"product_id\",\"periodo\",\"tn\",\"tn_mas_2\",\"tn_lag_1\",\"tn_delta_1\"]],how=\"inner\",on=[\"product_id\",\"periodo\"])\n",
    "df_test[[\"product_id\",\"periodo\",\"tn_x\",\"tn_y\",\"tn_mas_2_x\",\"tn_mas_2_y\",\"tn_lag_1_x\",\"tn_lag_1_y\",\"tn_delta_1_x\",\"tn_delta_1_y\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b63487a1-b78c-460f-b0a1-a865444a7cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn_x</th>\n",
       "      <th>tn_mas_2_x</th>\n",
       "      <th>tn_lag_1_x</th>\n",
       "      <th>tn_delta_1_x</th>\n",
       "      <th>valor_1</th>\n",
       "      <th>valor_2</th>\n",
       "      <th>tn_y</th>\n",
       "      <th>tn_mas_2_y</th>\n",
       "      <th>tn_lag_1_y</th>\n",
       "      <th>tn_delta_1_y</th>\n",
       "      <th>dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [product_id, periodo, tn_x, tn_mas_2_x, tn_lag_1_x, tn_delta_1_x, valor_1, valor_2, tn_y, tn_mas_2_y, tn_lag_1_y, tn_delta_1_y, dif]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compruebo que no haya diferencias\n",
    "df_test[\"dif\"]=df_test.tn_x-df_test.tn_y\n",
    "df_test[df_test.dif>1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce91fa0-4d65-4499-af51-857e4eb4bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>tn_x</th>\n",
       "      <th>tn_mas_2_x</th>\n",
       "      <th>tn_lag_1_x</th>\n",
       "      <th>tn_delta_1_x</th>\n",
       "      <th>valor_1</th>\n",
       "      <th>valor_2</th>\n",
       "      <th>tn_y</th>\n",
       "      <th>tn_mas_2_y</th>\n",
       "      <th>tn_lag_1_y</th>\n",
       "      <th>tn_delta_1_y</th>\n",
       "      <th>dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [product_id, periodo, tn_x, tn_mas_2_x, tn_lag_1_x, tn_delta_1_x, valor_1, valor_2, tn_y, tn_mas_2_y, tn_lag_1_y, tn_delta_1_y, dif]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.tn_x.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eae2452-a804-486e-9aad-9d65bb9c1d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformo todas las categoricas\n",
    "categories = [\"plan_precios_cuidados\",\"cat1\",\"cat2\",\"cat3\",\"product_id\"]\n",
    "\n",
    "for c in categories: \n",
    "    df_sellout_transf[c] = df_sellout_transf[c].astype(\"category\")   \n",
    "    \n",
    "#Elimino otras variables\n",
    "df_sellout_transf = df_sellout_transf.drop(columns=[\"brand\",\"periodo_fecha\",\"imputado\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7abd1511-90f1-4cfa-becd-8083ed34e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n",
      "868\n",
      "1055\n",
      "868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([201701, 201702, 201703, 201704, 201705, 201706, 201707, 201708,\n",
       "        201709, 201710, 201711, 201712, 201801, 201802, 201803, 201804,\n",
       "        201805, 201806, 201807, 201808, 201809, 201810], dtype=int64),\n",
       " array([201812], dtype=int64),\n",
       " array([201701, 201702, 201703, 201704, 201705, 201706, 201707, 201708,\n",
       "        201709, 201710, 201711, 201712, 201801, 201802, 201803, 201804,\n",
       "        201805, 201806, 201807, 201808, 201809, 201810, 201811, 201812],\n",
       "       dtype=int64),\n",
       " array([201902], dtype=int64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_sellout_transf[(df_sellout_transf.periodo <= train_periodo_limite) & (df_sellout_transf.periodo >= periodo_inicio)]\n",
    "df_validate = df_sellout_transf[df_sellout_transf.periodo == validate_periodo]\n",
    "\n",
    "df_train_all = df_sellout_transf[(df_sellout_transf.periodo <= train_all_periodo_limite) & (df_sellout_transf.periodo >= periodo_inicio)]\n",
    "df_holdout = df_sellout_transf[df_sellout_transf.periodo == holdout_periodo]\n",
    "# En validate y en test deben quedar 868 productos (son los productos a predecir)\n",
    "\n",
    "#En validate dejamos unicamente los productos a predecir\n",
    "print(len(df_validate))\n",
    "df_validate = df_validate[df_validate.product_id.isin(df_prods_prediccion.product_id)]\n",
    "df_validate = df_validate.sort_values(by=\"product_id\",ascending=True)\n",
    "print(len(df_validate))\n",
    "\n",
    "#Idem holdout\n",
    "print(len(df_holdout))\n",
    "df_holdout = df_holdout[df_holdout.product_id.isin(df_prods_prediccion.product_id)]\n",
    "df_holdout = df_holdout.sort_values(by=\"product_id\",ascending=True)\n",
    "print(len(df_holdout))\n",
    "\n",
    "df_train.periodo.unique(),df_validate.periodo.unique(),df_train_all.periodo.unique(),df_holdout.periodo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e58fbc7-f078-4836-adf0-6e3054374e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (20016, 143)\n",
      "y_train: (20016,)\n",
      "\n",
      "X_validate: (868, 143)\n",
      "y_validate: (868,)\n",
      "\n",
      "X_train_all: (22118, 143)\n",
      "y_train_all: (22118,)\n",
      "\n",
      "X_holdout: (868, 143)\n",
      "y_holdout: (868,)\n"
     ]
    }
   ],
   "source": [
    "# Train - Validate\n",
    "X_train = df_train.drop(columns=[\"tn_mas_2\",\"periodo\"], axis=1)\n",
    "X_validate = df_validate.drop(columns=[\"tn_mas_2\",\"periodo\"], axis=1)\n",
    "\n",
    "y_train = df_train.tn_mas_2\n",
    "y_validate = df_validate.tn_mas_2\n",
    "\n",
    "# Train All - Holdout\n",
    "X_train_all = df_train_all.drop(columns=[\"tn_mas_2\",\"periodo\"], axis=1)\n",
    "X_holdout = df_holdout.drop(columns=[\"tn_mas_2\",\"periodo\"], axis=1)\n",
    "\n",
    "y_train_all = df_train_all.tn_mas_2\n",
    "y_holdout = df_holdout.tn_mas_2\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "\n",
    "print(\"\\nX_validate:\", X_validate.shape)\n",
    "print(\"y_validate:\", y_validate.shape)\n",
    "\n",
    "print(\"\\nX_train_all:\", X_train_all.shape)\n",
    "print(\"y_train_all:\", y_train_all.shape)\n",
    "\n",
    "print(\"\\nX_holdout:\", X_holdout.shape)\n",
    "print(\"y_holdout:\", y_holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0d97621-262d-4ef6-a9b2-859171e8e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X_train.columns.tolist()\n",
    "\n",
    "lgb_train = lgb.Dataset(data=X_train, label=y_train, feature_name=cols)\n",
    "lgb_validate = lgb.Dataset(data=X_validate, label=y_validate, reference=lgb_train, feature_name=cols)\n",
    "lgbtrain_all = lgb.Dataset(data=X_train_all, label=y_train_all, feature_name=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34b671e8-66e8-4708-bf40-1fba9954688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Iteracion: 0 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 24.36\n",
      "[200]\tvalid_0's ER: 24.92\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's ER: 24.2\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.2  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 38\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 37\n",
      "bagging_freq: 8\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 1 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's ER: 30.18\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 30.18  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 81\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 74\n",
      "bagging_freq: 7\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 2 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 25.94\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's ER: 24.08\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.08  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 53\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 68\n",
      "bagging_freq: 9\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 3 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 25.56\n",
      "[200]\tvalid_0's ER: 24.6\n",
      "[300]\tvalid_0's ER: 24.63\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's ER: 24.35\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.35  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 45\n",
      "feature_fraction: 0.2\n",
      "min_data_in_leaf: 75\n",
      "bagging_freq: 5\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 4 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 24.16\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's ER: 23.76\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 23.76  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 94\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 57\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 5 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 30.73\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's ER: 28.4\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 28.4  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 26\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 94\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 6 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's ER: 35.23\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 35.23  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 54\n",
      "feature_fraction: 0.7\n",
      "min_data_in_leaf: 72\n",
      "bagging_freq: 4\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 7 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 27.94\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's ER: 26.25\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.25  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 89\n",
      "feature_fraction: 0.8\n",
      "min_data_in_leaf: 31\n",
      "bagging_freq: 8\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 8 -------------------------------------\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's ER: 30.24\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 30.24  ############\n",
      "learning_rate: 0.5\n",
      "num_leaves: 73\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 56\n",
      "bagging_freq: 1\n",
      "bagging_fraction: 0.9\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 9 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's ER: 35.89\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 35.89  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 28\n",
      "feature_fraction: 0.8\n",
      "min_data_in_leaf: 87\n",
      "bagging_freq: 4\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 10 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 26.84\n",
      "[200]\tvalid_0's ER: 26\n",
      "[300]\tvalid_0's ER: 25.58\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's ER: 25.22\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 25.22  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 95\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 96\n",
      "bagging_freq: 9\n",
      "bagging_fraction: 0.9\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 11 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's ER: 32.7\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 32.7  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 88\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 60\n",
      "bagging_freq: 6\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 12 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 29.65\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's ER: 27.58\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 27.58  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 95\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 90\n",
      "bagging_freq: 8\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 13 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 51.11\n",
      "[200]\tvalid_0's ER: 30.5\n",
      "[300]\tvalid_0's ER: 26.17\n",
      "[400]\tvalid_0's ER: 25.1\n",
      "[500]\tvalid_0's ER: 24.97\n",
      "[600]\tvalid_0's ER: 24.85\n",
      "[700]\tvalid_0's ER: 24.66\n",
      "[800]\tvalid_0's ER: 24.59\n",
      "[900]\tvalid_0's ER: 24.43\n",
      "[1000]\tvalid_0's ER: 24.43\n",
      "[1100]\tvalid_0's ER: 24.47\n",
      "[1200]\tvalid_0's ER: 24.33\n",
      "[1300]\tvalid_0's ER: 24.41\n",
      "[1400]\tvalid_0's ER: 24.4\n",
      "[1500]\tvalid_0's ER: 24.44\n",
      "Early stopping, best iteration is:\n",
      "[955]\tvalid_0's ER: 24.3\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.3  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 61\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 52\n",
      "bagging_freq: 4\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 14 -------------------------------------\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's ER: 33.51\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 33.51  ############\n",
      "learning_rate: 0.5\n",
      "num_leaves: 75\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 61\n",
      "bagging_freq: 7\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 15 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 30.89\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's ER: 30.17\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 30.17  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 57\n",
      "feature_fraction: 0.2\n",
      "min_data_in_leaf: 12\n",
      "bagging_freq: 3\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 16 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 28.19\n",
      "[200]\tvalid_0's ER: 28.57\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's ER: 28.01\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 28.01  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 35\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 8\n",
      "bagging_freq: 1\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 17 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 54.9\n",
      "[200]\tvalid_0's ER: 32.43\n",
      "[300]\tvalid_0's ER: 27.5\n",
      "[400]\tvalid_0's ER: 26.23\n",
      "[500]\tvalid_0's ER: 25.99\n",
      "[600]\tvalid_0's ER: 25.85\n",
      "[700]\tvalid_0's ER: 25.87\n",
      "[800]\tvalid_0's ER: 25.78\n",
      "[900]\tvalid_0's ER: 25.88\n",
      "[1000]\tvalid_0's ER: 25.95\n",
      "[1100]\tvalid_0's ER: 25.85\n",
      "[1200]\tvalid_0's ER: 25.85\n",
      "[1300]\tvalid_0's ER: 25.75\n",
      "[1400]\tvalid_0's ER: 25.69\n",
      "[1500]\tvalid_0's ER: 25.67\n",
      "[1600]\tvalid_0's ER: 25.63\n",
      "[1700]\tvalid_0's ER: 25.74\n",
      "[1800]\tvalid_0's ER: 25.72\n",
      "[1900]\tvalid_0's ER: 25.69\n",
      "[2000]\tvalid_0's ER: 25.7\n",
      "[2100]\tvalid_0's ER: 25.78\n",
      "Early stopping, best iteration is:\n",
      "[1572]\tvalid_0's ER: 25.59\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 25.59  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 50\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 20\n",
      "bagging_freq: 6\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 18 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's ER: 32.19\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 32.19  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 75\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 69\n",
      "bagging_freq: 9\n",
      "bagging_fraction: 0.75\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 19 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 52.62\n",
      "[200]\tvalid_0's ER: 30.93\n",
      "[300]\tvalid_0's ER: 26.97\n",
      "[400]\tvalid_0's ER: 26.31\n",
      "[500]\tvalid_0's ER: 26.38\n",
      "[600]\tvalid_0's ER: 26.42\n",
      "[700]\tvalid_0's ER: 26.34\n",
      "[800]\tvalid_0's ER: 26.52\n",
      "[900]\tvalid_0's ER: 26.33\n",
      "[1000]\tvalid_0's ER: 26.23\n",
      "[1100]\tvalid_0's ER: 26.19\n",
      "[1200]\tvalid_0's ER: 26.23\n",
      "[1300]\tvalid_0's ER: 26.19\n",
      "[1400]\tvalid_0's ER: 26.16\n",
      "[1500]\tvalid_0's ER: 26.12\n",
      "[1600]\tvalid_0's ER: 26.09\n",
      "[1700]\tvalid_0's ER: 26.12\n",
      "[1800]\tvalid_0's ER: 26.08\n",
      "[1900]\tvalid_0's ER: 26.11\n",
      "[2000]\tvalid_0's ER: 26.1\n",
      "Early stopping, best iteration is:\n",
      "[1516]\tvalid_0's ER: 26.07\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.07  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 78\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 7\n",
      "bagging_freq: 5\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 20 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 50.83\n",
      "[200]\tvalid_0's ER: 30.82\n",
      "[300]\tvalid_0's ER: 26.44\n",
      "[400]\tvalid_0's ER: 25.6\n",
      "[500]\tvalid_0's ER: 25.35\n",
      "[600]\tvalid_0's ER: 25.09\n",
      "[700]\tvalid_0's ER: 24.73\n",
      "[800]\tvalid_0's ER: 24.6\n",
      "[900]\tvalid_0's ER: 24.28\n",
      "[1000]\tvalid_0's ER: 24.09\n",
      "[1100]\tvalid_0's ER: 23.97\n",
      "[1200]\tvalid_0's ER: 23.85\n",
      "[1300]\tvalid_0's ER: 23.84\n",
      "[1400]\tvalid_0's ER: 23.86\n",
      "[1500]\tvalid_0's ER: 23.82\n",
      "[1600]\tvalid_0's ER: 23.76\n",
      "[1700]\tvalid_0's ER: 23.77\n",
      "[1800]\tvalid_0's ER: 23.79\n",
      "[1900]\tvalid_0's ER: 23.82\n",
      "[2000]\tvalid_0's ER: 23.78\n",
      "[2100]\tvalid_0's ER: 23.79\n",
      "Early stopping, best iteration is:\n",
      "[1617]\tvalid_0's ER: 23.73\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 23.73  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 90\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 83\n",
      "bagging_freq: 9\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 21 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 52.59\n",
      "[200]\tvalid_0's ER: 32.39\n",
      "[300]\tvalid_0's ER: 28.08\n",
      "[400]\tvalid_0's ER: 27.17\n",
      "[500]\tvalid_0's ER: 26.81\n",
      "[600]\tvalid_0's ER: 26.75\n",
      "[700]\tvalid_0's ER: 26.5\n",
      "[800]\tvalid_0's ER: 26.33\n",
      "[900]\tvalid_0's ER: 25.93\n",
      "[1000]\tvalid_0's ER: 25.7\n",
      "[1100]\tvalid_0's ER: 25.45\n",
      "[1200]\tvalid_0's ER: 25.31\n",
      "[1300]\tvalid_0's ER: 25.24\n",
      "[1400]\tvalid_0's ER: 25.1\n",
      "[1500]\tvalid_0's ER: 25.02\n",
      "[1600]\tvalid_0's ER: 24.89\n",
      "[1700]\tvalid_0's ER: 24.79\n",
      "[1800]\tvalid_0's ER: 24.76\n",
      "[1900]\tvalid_0's ER: 24.65\n",
      "[2000]\tvalid_0's ER: 24.6\n",
      "[2100]\tvalid_0's ER: 24.59\n",
      "[2200]\tvalid_0's ER: 24.41\n",
      "[2300]\tvalid_0's ER: 24.31\n",
      "[2400]\tvalid_0's ER: 24.37\n",
      "[2500]\tvalid_0's ER: 24.35\n",
      "[2600]\tvalid_0's ER: 24.36\n",
      "[2700]\tvalid_0's ER: 24.3\n",
      "[2800]\tvalid_0's ER: 24.29\n",
      "[2900]\tvalid_0's ER: 24.27\n",
      "[3000]\tvalid_0's ER: 24.32\n",
      "[3100]\tvalid_0's ER: 24.35\n",
      "[3200]\tvalid_0's ER: 24.38\n",
      "[3300]\tvalid_0's ER: 24.38\n",
      "Early stopping, best iteration is:\n",
      "[2835]\tvalid_0's ER: 24.25\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.25  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 39\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 81\n",
      "bagging_freq: 5\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 22 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 52.86\n",
      "[200]\tvalid_0's ER: 33.04\n",
      "[300]\tvalid_0's ER: 28.63\n",
      "[400]\tvalid_0's ER: 27.23\n",
      "[500]\tvalid_0's ER: 26.85\n",
      "[600]\tvalid_0's ER: 26.55\n",
      "[700]\tvalid_0's ER: 26.47\n",
      "[800]\tvalid_0's ER: 26.18\n",
      "[900]\tvalid_0's ER: 26.02\n",
      "[1000]\tvalid_0's ER: 25.95\n",
      "[1100]\tvalid_0's ER: 25.72\n",
      "[1200]\tvalid_0's ER: 25.69\n",
      "[1300]\tvalid_0's ER: 25.58\n",
      "[1400]\tvalid_0's ER: 25.46\n",
      "[1500]\tvalid_0's ER: 25.34\n",
      "[1600]\tvalid_0's ER: 25.26\n",
      "[1700]\tvalid_0's ER: 25.2\n",
      "[1800]\tvalid_0's ER: 25.09\n",
      "[1900]\tvalid_0's ER: 24.89\n",
      "[2000]\tvalid_0's ER: 24.96\n",
      "[2100]\tvalid_0's ER: 24.91\n",
      "[2200]\tvalid_0's ER: 24.84\n",
      "[2300]\tvalid_0's ER: 24.82\n",
      "[2400]\tvalid_0's ER: 24.72\n",
      "[2500]\tvalid_0's ER: 24.67\n",
      "[2600]\tvalid_0's ER: 24.58\n",
      "[2700]\tvalid_0's ER: 24.53\n",
      "[2800]\tvalid_0's ER: 24.5\n",
      "[2900]\tvalid_0's ER: 24.47\n",
      "[3000]\tvalid_0's ER: 24.42\n",
      "[3100]\tvalid_0's ER: 24.38\n",
      "[3200]\tvalid_0's ER: 24.37\n",
      "[3300]\tvalid_0's ER: 24.45\n",
      "[3400]\tvalid_0's ER: 24.47\n",
      "[3500]\tvalid_0's ER: 24.49\n",
      "[3600]\tvalid_0's ER: 24.56\n",
      "[3700]\tvalid_0's ER: 24.68\n",
      "Early stopping, best iteration is:\n",
      "[3171]\tvalid_0's ER: 24.33\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.33  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 87\n",
      "feature_fraction: 0.7\n",
      "min_data_in_leaf: 82\n",
      "bagging_freq: 6\n",
      "bagging_fraction: 0.75\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 23 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's ER: 33.89\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 33.89  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 95\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 86\n",
      "bagging_freq: 3\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 24 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's ER: 32.33\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 32.33  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 69\n",
      "feature_fraction: 0.7\n",
      "min_data_in_leaf: 57\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 25 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 30.28\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's ER: 29.39\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 29.39  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 92\n",
      "feature_fraction: 0.2\n",
      "min_data_in_leaf: 2\n",
      "bagging_freq: 9\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 26 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 26.46\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's ER: 25.26\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 25.26  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 51\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 26\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.9\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 27 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 23.38\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's ER: 23.04\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 23.04  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 82\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 45\n",
      "bagging_freq: 4\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 28 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 26.53\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's ER: 25.93\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 25.93  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 93\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 86\n",
      "bagging_freq: 9\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 29 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 23.8\n",
      "[200]\tvalid_0's ER: 23.18\n",
      "[300]\tvalid_0's ER: 23.26\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's ER: 22.93\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 22.93  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 41\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 86\n",
      "bagging_freq: 1\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 30 -------------------------------------\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's ER: 27.29\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 27.29  ############\n",
      "learning_rate: 0.5\n",
      "num_leaves: 51\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 95\n",
      "bagging_freq: 5\n",
      "bagging_fraction: 0.75\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 31 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's ER: 37.74\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 37.74  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 68\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 77\n",
      "bagging_freq: 1\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 32 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 54.26\n",
      "[200]\tvalid_0's ER: 32.18\n",
      "[300]\tvalid_0's ER: 27.5\n",
      "[400]\tvalid_0's ER: 26.73\n",
      "[500]\tvalid_0's ER: 26.59\n",
      "[600]\tvalid_0's ER: 26.64\n",
      "[700]\tvalid_0's ER: 26.44\n",
      "[800]\tvalid_0's ER: 26.33\n",
      "[900]\tvalid_0's ER: 26.19\n",
      "[1000]\tvalid_0's ER: 26.19\n",
      "[1100]\tvalid_0's ER: 26.19\n",
      "[1200]\tvalid_0's ER: 26.15\n",
      "[1300]\tvalid_0's ER: 26.07\n",
      "[1400]\tvalid_0's ER: 26.05\n",
      "[1500]\tvalid_0's ER: 26.07\n",
      "[1600]\tvalid_0's ER: 26.04\n",
      "[1700]\tvalid_0's ER: 26.04\n",
      "[1800]\tvalid_0's ER: 26.03\n",
      "[1900]\tvalid_0's ER: 25.97\n",
      "[2000]\tvalid_0's ER: 25.9\n",
      "[2100]\tvalid_0's ER: 25.86\n",
      "[2200]\tvalid_0's ER: 25.86\n",
      "[2300]\tvalid_0's ER: 25.81\n",
      "[2400]\tvalid_0's ER: 25.81\n",
      "[2500]\tvalid_0's ER: 25.81\n",
      "[2600]\tvalid_0's ER: 25.78\n",
      "[2700]\tvalid_0's ER: 25.75\n",
      "[2800]\tvalid_0's ER: 25.75\n",
      "[2900]\tvalid_0's ER: 25.7\n",
      "[3000]\tvalid_0's ER: 25.72\n",
      "[3100]\tvalid_0's ER: 25.74\n",
      "[3200]\tvalid_0's ER: 25.75\n",
      "[3300]\tvalid_0's ER: 25.75\n",
      "[3400]\tvalid_0's ER: 25.75\n",
      "Early stopping, best iteration is:\n",
      "[2874]\tvalid_0's ER: 25.7\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 25.7  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 90\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 6\n",
      "bagging_freq: 7\n",
      "bagging_fraction: 0.75\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 33 -------------------------------------\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's ER: 32.41\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 32.41  ############\n",
      "learning_rate: 0.5\n",
      "num_leaves: 22\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 99\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 34 -------------------------------------\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's ER: 27.56\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 27.56  ############\n",
      "learning_rate: 0.5\n",
      "num_leaves: 48\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 57\n",
      "bagging_freq: 8\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 35 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 25.31\n",
      "[200]\tvalid_0's ER: 25.25\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's ER: 24.74\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.74  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 29\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 36\n",
      "bagging_freq: 5\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 36 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's ER: 36.45\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 36.45  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 95\n",
      "feature_fraction: 0.7\n",
      "min_data_in_leaf: 54\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 37 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 26.97\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's ER: 26.9\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.9  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 60\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 95\n",
      "bagging_freq: 3\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 38 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 28.82\n",
      "[200]\tvalid_0's ER: 27\n",
      "[300]\tvalid_0's ER: 27.3\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's ER: 26.99\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.99  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 32\n",
      "feature_fraction: 0.2\n",
      "min_data_in_leaf: 50\n",
      "bagging_freq: 6\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 39 -------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's ER: 25.87\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's ER: 24.75\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.75  ############\n",
      "learning_rate: 0.1\n",
      "num_leaves: 70\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 30\n",
      "bagging_freq: 7\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 40 -------------------------------------\n",
      "Training until validation scores don't improve for 60 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's ER: 26.54\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.54  ############\n",
      "learning_rate: 0.5\n",
      "num_leaves: 27\n",
      "feature_fraction: 0.8\n",
      "min_data_in_leaf: 26\n",
      "bagging_freq: 6\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 41 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 27.54\n",
      "[200]\tvalid_0's ER: 27.11\n",
      "[300]\tvalid_0's ER: 26.38\n",
      "[400]\tvalid_0's ER: 26.56\n",
      "[500]\tvalid_0's ER: 26.67\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's ER: 26.14\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.14  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 25\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 71\n",
      "bagging_freq: 3\n",
      "bagging_fraction: 0.7\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 42 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 25.28\n",
      "[200]\tvalid_0's ER: 24.85\n",
      "[300]\tvalid_0's ER: 24.76\n",
      "[400]\tvalid_0's ER: 24.79\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid_0's ER: 24.63\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.63  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 63\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 61\n",
      "bagging_freq: 5\n",
      "bagging_fraction: 0.85\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 43 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 50.67\n",
      "[200]\tvalid_0's ER: 30.3\n",
      "[300]\tvalid_0's ER: 25.88\n",
      "[400]\tvalid_0's ER: 24.84\n",
      "[500]\tvalid_0's ER: 24.45\n",
      "[600]\tvalid_0's ER: 24.11\n",
      "[700]\tvalid_0's ER: 23.96\n",
      "[800]\tvalid_0's ER: 24.08\n",
      "[900]\tvalid_0's ER: 24.14\n",
      "[1000]\tvalid_0's ER: 24.12\n",
      "[1100]\tvalid_0's ER: 24\n",
      "[1200]\tvalid_0's ER: 24.05\n",
      "Early stopping, best iteration is:\n",
      "[708]\tvalid_0's ER: 23.9\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 23.9  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 98\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 52\n",
      "bagging_freq: 4\n",
      "bagging_fraction: 0.75\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 44 -------------------------------------\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\tvalid_0's ER: 25.47\n",
      "[200]\tvalid_0's ER: 25.51\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's ER: 25.22\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 25.22  ############\n",
      "learning_rate: 0.05\n",
      "num_leaves: 87\n",
      "feature_fraction: 0.9\n",
      "min_data_in_leaf: 32\n",
      "bagging_freq: 7\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 45 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 51.43\n",
      "[200]\tvalid_0's ER: 30.25\n",
      "[300]\tvalid_0's ER: 25.9\n",
      "[400]\tvalid_0's ER: 24.94\n",
      "[500]\tvalid_0's ER: 24.74\n",
      "[600]\tvalid_0's ER: 24.55\n",
      "[700]\tvalid_0's ER: 24.55\n",
      "[800]\tvalid_0's ER: 24.68\n",
      "[900]\tvalid_0's ER: 24.74\n",
      "[1000]\tvalid_0's ER: 24.76\n",
      "[1100]\tvalid_0's ER: 24.83\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's ER: 24.49\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.49  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 40\n",
      "feature_fraction: 0.3\n",
      "min_data_in_leaf: 41\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.9\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 46 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 50.01\n",
      "[200]\tvalid_0's ER: 29.21\n",
      "[300]\tvalid_0's ER: 24.53\n",
      "[400]\tvalid_0's ER: 22.81\n",
      "[500]\tvalid_0's ER: 22.54\n",
      "[600]\tvalid_0's ER: 22.79\n",
      "[700]\tvalid_0's ER: 22.7\n",
      "[800]\tvalid_0's ER: 22.97\n",
      "[900]\tvalid_0's ER: 23.11\n",
      "[1000]\tvalid_0's ER: 23.23\n",
      "Early stopping, best iteration is:\n",
      "[499]\tvalid_0's ER: 22.52\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 22.52  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 99\n",
      "feature_fraction: 0.7\n",
      "min_data_in_leaf: 43\n",
      "bagging_freq: 8\n",
      "bagging_fraction: 0.8\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 47 -------------------------------------\n",
      "Training until validation scores don't improve for 550 rounds\n",
      "[100]\tvalid_0's ER: 50.9\n",
      "[200]\tvalid_0's ER: 29.03\n",
      "[300]\tvalid_0's ER: 25.15\n",
      "[400]\tvalid_0's ER: 24.89\n",
      "[500]\tvalid_0's ER: 25.07\n",
      "[600]\tvalid_0's ER: 25.16\n",
      "[700]\tvalid_0's ER: 25.19\n",
      "[800]\tvalid_0's ER: 25.25\n",
      "[900]\tvalid_0's ER: 25.29\n",
      "Early stopping, best iteration is:\n",
      "[363]\tvalid_0's ER: 24.87\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 24.87  ############\n",
      "learning_rate: 0.01\n",
      "num_leaves: 95\n",
      "feature_fraction: 0.4\n",
      "min_data_in_leaf: 8\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "------------------------------------- Iteracion: 48 -------------------------------------\n",
      "Training until validation scores don't improve for 75 rounds\n",
      "[100]\tvalid_0's ER: 27.76\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's ER: 26.77\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 26.77  ############\n",
      "learning_rate: 0.2\n",
      "num_leaves: 55\n",
      "feature_fraction: 0.6\n",
      "min_data_in_leaf: 91\n",
      "bagging_freq: 6\n",
      "bagging_fraction: 0.9\n",
      "extra_trees: True\n",
      "\n",
      "------------------------------------- Iteracion: 49 -------------------------------------\n",
      "Training until validation scores don't improve for 55 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's ER: 29.35\n",
      "Evaluated only: ER\n",
      "\n",
      " ############ Error Rate: 29.35  ############\n",
      "learning_rate: 0.9\n",
      "num_leaves: 54\n",
      "feature_fraction: 0.5\n",
      "min_data_in_leaf: 30\n",
      "bagging_freq: 2\n",
      "bagging_fraction: 0.95\n",
      "extra_trees: False\n",
      "\n",
      "\n",
      "*********** Minimum is:  22.52 ***********\n"
     ]
    }
   ],
   "source": [
    "min_er = 100 \n",
    "count = 0 #Used for keeping track of the iteration number\n",
    "params_iter = []\n",
    "er_validate_iter = []\n",
    "er_holdout_iter = []\n",
    "\n",
    "for i in range(iteraciones_random_search):\n",
    "    print('\\n------------------------------------- Iteracion:', count,\"-------------------------------------\")\n",
    "    count += 1\n",
    "    \n",
    "    lgb_params = {}\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['first_metric_only']= True\n",
    "    lgb_params['boost_from_average']= True\n",
    "    lgb_params['max_bin']= 31 ###revisar\n",
    "    lgb_params['max_depth']= -1 # -1 significa no limitar\n",
    "    lgb_params['min_gain_to_split']= 0.0 #fijo\n",
    "    lgb_params['lambda_l1']= 0.0 #fijo\n",
    "    lgb_params['lambda_l2']= 0.0 #fijo\n",
    "    lgb_params['force_row_wise']= True   #para evitar tantos warning\n",
    "    lgb_params['feature_pre_filter']= False\n",
    "    lgb_params['metric']=\"None\"\n",
    "\n",
    "    lgb_params['learning_rate'] = np.random.choice([0.01,0.05,0.1,0.2,0.5,0.9])\n",
    "    lgb_params['num_leaves'] = np.random.randint(20, 100)\n",
    "    lgb_params['feature_fraction'] = np.random.choice([0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "    lgb_params['min_data_in_leaf'] = np.random.randint(0, 100)\n",
    "   \n",
    "    lgb_params['bagging_freq']=  np.random.randint(1, 10)\n",
    "    lgb_params['bagging_fraction']=  np.random.choice([0.7,0.75,0.8,0.85,0.9,0.95])\n",
    "    lgb_params['extra_trees']= np.random.choice([True,False])\n",
    "    lgb_params['verbose'] = -100\n",
    "    lgb_params['num_threads'] = -1\n",
    "\n",
    "    lgb_params_num_boost_round = 10000  #un numero muy grande, lo limita early_stopping_rounds\n",
    "    lgb_params_early_stopping_rounds = int(50 + 5/lgb_params['learning_rate']) #  #el parametro discolo, que depende de otro\n",
    "\n",
    "    #Antes de entrenar, se setea vector global para validate\n",
    "    GLOBAL_PRODUCT_IDS = actualizar_global_prods(y_validate_orig)\n",
    "    \n",
    "    #Train using selected parameters\n",
    "    model = lgb.train(lgb_params, lgb_train,\n",
    "                  valid_sets=[lgb_validate],\n",
    "                  num_boost_round=lgb_params_num_boost_round,\n",
    "                  early_stopping_rounds=lgb_params_early_stopping_rounds,\n",
    "                  feval=lgbm_error_rate,\n",
    "                  verbose_eval=100)\n",
    "    \n",
    "    y_pred_validate =model.predict(X_validate) #Create predictions on test set\n",
    "    er_validate = error_rate(y_validate,y_pred_validate)\n",
    "    \n",
    "    params_iter.append(lgb_params)\n",
    "    er_validate_iter.append(er_validate)\n",
    "    \n",
    "    print('\\n ############ Error Rate:', er_validate,\" ############\")\n",
    "    print(\"learning_rate:\",lgb_params['learning_rate'])\n",
    "    print(\"num_leaves:\",lgb_params['num_leaves'])\n",
    "    print(\"feature_fraction:\",lgb_params['feature_fraction'])\n",
    "    print(\"min_data_in_leaf:\",lgb_params['min_data_in_leaf'])\n",
    "    print(\"bagging_freq:\",lgb_params['bagging_freq'])\n",
    "    print(\"bagging_fraction:\",lgb_params['bagging_fraction'])\n",
    "    print(\"extra_trees:\",lgb_params['extra_trees'])\n",
    "\n",
    "    #Actualizo mejor modelo\n",
    "    if er_validate < min_er:\n",
    "        min_er = er_validate\n",
    "        best_lgb_params = lgb_params \n",
    "        best_model = model\n",
    "\n",
    "    # Antes de entrenar full, cambio vector global por holdout\n",
    "    GLOBAL_PRODUCT_IDS = actualizar_global_prods(y_holdout_orig)\n",
    "    \n",
    "    #Entreno full train y guardo error de holdout\n",
    "    final_model = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model.best_iteration)\n",
    "    y_pred_holdout = final_model.predict(X_holdout)\n",
    "    er_holdout = error_rate(y_holdout,y_pred_holdout)\n",
    "    er_holdout_iter.append(er_holdout)\n",
    "\n",
    "print('\\n\\n*********** Minimum is: ', min_er, \"***********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f926ed92-0616-47bf-86f5-a046859bb2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>split</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_id</td>\n",
       "      <td>3517</td>\n",
       "      <td>51.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cust_request_tn</td>\n",
       "      <td>1512</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tn</td>\n",
       "      <td>1571</td>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>producto_estrella</td>\n",
       "      <td>171</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tn_lag_1</td>\n",
       "      <td>1768</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>cat1_tn_delta_15</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>cat1_tn_lag_15</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plan_precios_cuidados</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>catastrofe</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  split  gain\n",
       "0              product_id   3517 51.43\n",
       "2         cust_request_tn   1512 22.38\n",
       "1                      tn   1571  7.76\n",
       "11      producto_estrella    171  4.25\n",
       "20               tn_lag_1   1768  2.74\n",
       "..                    ...    ...   ...\n",
       "80       cat1_tn_delta_15     40  0.00\n",
       "79         cat1_tn_lag_15     31  0.00\n",
       "7                    cat1      4  0.00\n",
       "4   plan_precios_cuidados      2  0.00\n",
       "17             catastrofe      0  0.00\n",
       "\n",
       "[143 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_lgb_importances(best_model, num=30, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d221428b-e80c-435b-92cd-114bec21683e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.52"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOBAL_PRODUCT_IDS = actualizar_global_prods(y_validate_orig)\n",
    "\n",
    "y_pred_validate = best_model.predict(X_validate)\n",
    "er_validate = error_rate(y_validate,y_pred_validate)\n",
    "er_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0935c-52eb-4c11-baf2-e1c1178059f1",
   "metadata": {},
   "source": [
    "## Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87b4783e-d9d9-4f53-8911-4bb40131e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = lgb.train(best_lgb_params, lgbtrain_all, num_boost_round=best_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b8ebb01-9b14-49ad-9532-4eeb506f741b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOBAL_PRODUCT_IDS = actualizar_global_prods(y_holdout_orig)\n",
    "\n",
    "y_pred_holdout = final_model.predict(X_holdout)\n",
    "er_holdout = error_rate(y_holdout,y_pred_holdout)\n",
    "er_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef018cb4-8e69-41c6-b300-a15156afc023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(868, 143)\n",
      "(868, 145)\n"
     ]
    }
   ],
   "source": [
    "print(X_holdout.shape)\n",
    "df_prediccion = X_holdout.copy()\n",
    "df_prediccion[\"tn_target\"]=np.array(y_holdout_orig)\n",
    "df_prediccion[\"tn_predicted\"]=np.array(destransformar_vector(y_pred_holdout))\n",
    "print(df_prediccion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4687375c-c603-4639-8e8d-fc882e751cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toneladas Holdout:\t 33763.86541\n",
      "Toneladas Prediccion:\t 32371.109409279637\n"
     ]
    }
   ],
   "source": [
    "print(\"Toneladas Holdout:\\t\", df_prediccion.tn_target.sum())\n",
    "print(\"Toneladas Prediccion:\\t\", df_prediccion.tn_predicted.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "572f3223-779c-42d8-822e-fd4c51680032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediccion = df_prediccion.sort_values(by=\"product_id\",ascending=True)\n",
    "df_prediccion.to_csv(arch_predicciones_full, index=False)\n",
    "df_prediccion[[\"product_id\",\"tn_predicted\"]].to_csv(arch_predicciones_simple, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4095edf-6af3-4f7a-80fe-53ce6e753a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate Validate: 22.52\n",
      "Error Rate Holdout: 25.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Rate Validate:\",er_validate)\n",
    "print(\"Error Rate Holdout:\",er_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6171fb7d-cdf0-448e-b507-001d617ba46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression',\n",
       " 'first_metric_only': True,\n",
       " 'boost_from_average': True,\n",
       " 'max_bin': 31,\n",
       " 'max_depth': -1,\n",
       " 'min_gain_to_split': 0.0,\n",
       " 'lambda_l1': 0.0,\n",
       " 'lambda_l2': 0.0,\n",
       " 'force_row_wise': True,\n",
       " 'feature_pre_filter': False,\n",
       " 'metric': 'None',\n",
       " 'learning_rate': 0.01,\n",
       " 'num_leaves': 99,\n",
       " 'feature_fraction': 0.7,\n",
       " 'min_data_in_leaf': 43,\n",
       " 'bagging_freq': 8,\n",
       " 'bagging_fraction': 0.8,\n",
       " 'extra_trees': False,\n",
       " 'verbose': -100,\n",
       " 'num_threads': -1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eed8479f-261b-46cc-8481-86af74b9b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado = pd.DataFrame(data={\"error_rate_validation\":er_validate_iter,\"error_rate_holdout\": er_holdout_iter, \"params\":params_iter})\n",
    "\n",
    "datetime_string = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M')\n",
    "df_resultado.to_excel(\"resultados_random_search_\"+GLOBAL_TRANSF+\"_\"+str(iteraciones_random_search)+\"_\"+datetime_string+\".xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4c42d26-9218-4b50-b544-b72da6f33c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 500  # 1000 milliseconds = 1 second\n",
    "winsound.Beep(2000, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
