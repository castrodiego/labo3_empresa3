{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cca832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "####################################################\n",
    "############# Setear segun cada maquina ############\n",
    "os.chdir(\"C:/Users/herna/labo3_empresa3_repo/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2dd467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File in: emp3_sellout_lags_deltalags_product_categorias_sin_norm.csv\n",
      "File out: emp3_sellout_base_period_product_FE_sin_norm.csv\n"
     ]
    }
   ],
   "source": [
    "#selecciono que archivo procesar segun el tipo de transformacion a tilizar\n",
    "#//sin_norm=sin normalizacion //cero_uno=min max (0-1) //media_sd=standard media y desvio\n",
    "tipos_norm = ['sin_norm', 'cero_uno', 'media_sd']\n",
    "\n",
    "normalizacion = tipos_norm[0] \n",
    "\n",
    "#data = \"emp3_sellout_base_period_product.csv\"\n",
    "data_entrada = \"emp3_sellout_lags_deltalags_product_categorias\" #FE que dejo el NB de EMi BASE\n",
    "data_salida = \"emp3_sellout_base_period_product_FE\"\n",
    "\n",
    "if normalizacion == tipos_norm[0]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n",
    "    \n",
    "elif normalizacion == tipos_norm[1]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n",
    "    \n",
    "elif normalizacion == tipos_norm[2]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb6bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31243 entries, 0 to 31242\n",
      "Columns: 300 entries, periodo to cat3_delta_lag_35\n",
      "dtypes: bool(1), float64(292), int64(3), object(4)\n",
      "memory usage: 71.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Lea el Dataset base\n",
    "df = pd.read_csv(data_entrada)\n",
    "\n",
    "columnas_a_eliminar = ['periodo']\n",
    "df = df.drop(columnas_a_eliminar, axis=1)\n",
    "df = df.rename(columns={'periodo_fecha': 'periodo'})\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeba781",
   "metadata": {},
   "source": [
    "**setting the parametros generales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75171d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#periods_to_train = ['2019-10-01','2019-09-01','2019-08-01','2019-07-01','2019-06-01','2019-05-01','2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01' ]\n",
    "#periods_to_train = ['2019-10-01']\n",
    "#de Abril 2019 y 13 meses hacia atras\n",
    "periods_to_train = ['2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01','2018-10-01','2018-09-01','2018-08-01','2018-07-01','2018-06-01','2018-05-01','2018-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a32a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando periodo: 2019-04-01\n",
      "periodo tn_2: 2019-06-01\n",
      "Fecha ini lags: 2018-03-01\n",
      "Fecha fin lags: 2019-04-01\n",
      "mean from: 2019-03-01\n",
      "mean to -2 2019-02-01\n",
      "mean to -3 2019-01-01\n",
      "mean to -6 2018-10-01\n",
      "mean to -12 2018-04-01\n",
      "q from: 2019-03-01\n",
      "q to: 2019-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "Procesando periodo: 2019-03-01\n",
      "periodo tn_2: 2019-05-01\n",
      "Fecha ini lags: 2018-02-01\n",
      "Fecha fin lags: 2019-03-01\n",
      "mean from: 2019-02-01\n",
      "mean to -2 2019-01-01\n",
      "mean to -3 2018-12-01\n",
      "mean to -6 2018-09-01\n",
      "mean to -12 2018-03-01\n",
      "q from: 2019-02-01\n",
      "q to: 2018-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "Procesando periodo: 2019-02-01\n",
      "periodo tn_2: 2019-04-01\n",
      "Fecha ini lags: 2018-01-01\n",
      "Fecha fin lags: 2019-02-01\n",
      "mean from: 2019-01-01\n",
      "mean to -2 2018-12-01\n",
      "mean to -3 2018-11-01\n",
      "mean to -6 2018-08-01\n",
      "mean to -12 2018-02-01\n",
      "q from: 2019-01-01\n",
      "q to: 2018-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "Procesando periodo: 2019-01-01\n",
      "periodo tn_2: 2019-03-01\n",
      "Fecha ini lags: 2017-12-01\n",
      "Fecha fin lags: 2019-01-01\n",
      "mean from: 2018-12-01\n",
      "mean to -2 2018-11-01\n",
      "mean to -3 2018-10-01\n",
      "mean to -6 2018-07-01\n",
      "mean to -12 2018-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "Procesando periodo: 2018-12-01\n",
      "periodo tn_2: 2019-02-01\n",
      "Fecha ini lags: 2017-11-01\n",
      "Fecha fin lags: 2018-12-01\n",
      "mean from: 2018-11-01\n",
      "mean to -2 2018-10-01\n",
      "mean to -3 2018-09-01\n",
      "mean to -6 2018-06-01\n",
      "mean to -12 2017-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "Procesando periodo: 2018-11-01\n",
      "periodo tn_2: 2019-01-01\n",
      "Fecha ini lags: 2017-10-01\n",
      "Fecha fin lags: 2018-11-01\n",
      "mean from: 2018-10-01\n",
      "mean to -2 2018-09-01\n",
      "mean to -3 2018-08-01\n",
      "mean to -6 2018-05-01\n",
      "mean to -12 2017-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "Procesando periodo: 2018-10-01\n",
      "periodo tn_2: 2018-12-01\n",
      "Fecha ini lags: 2017-09-01\n",
      "Fecha fin lags: 2018-10-01\n",
      "mean from: 2018-09-01\n",
      "mean to -2 2018-08-01\n",
      "mean to -3 2018-07-01\n",
      "mean to -6 2018-04-01\n",
      "mean to -12 2017-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "Procesando periodo: 2018-09-01\n",
      "periodo tn_2: 2018-11-01\n",
      "Fecha ini lags: 2017-08-01\n",
      "Fecha fin lags: 2018-09-01\n",
      "mean from: 2018-08-01\n",
      "mean to -2 2018-07-01\n",
      "mean to -3 2018-06-01\n",
      "mean to -6 2018-03-01\n",
      "mean to -12 2017-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "Procesando periodo: 2018-08-01\n",
      "periodo tn_2: 2018-10-01\n",
      "Fecha ini lags: 2017-07-01\n",
      "Fecha fin lags: 2018-08-01\n",
      "mean from: 2018-07-01\n",
      "mean to -2 2018-06-01\n",
      "mean to -3 2018-05-01\n",
      "mean to -6 2018-02-01\n",
      "mean to -12 2017-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "Procesando periodo: 2018-07-01\n",
      "periodo tn_2: 2018-09-01\n",
      "Fecha ini lags: 2017-06-01\n",
      "Fecha fin lags: 2018-07-01\n",
      "mean from: 2018-06-01\n",
      "mean to -2 2018-05-01\n",
      "mean to -3 2018-04-01\n",
      "mean to -6 2018-01-01\n",
      "mean to -12 2017-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "Procesando periodo: 2018-06-01\n",
      "periodo tn_2: 2018-08-01\n",
      "Fecha ini lags: 2017-05-01\n",
      "Fecha fin lags: 2018-06-01\n",
      "mean from: 2018-05-01\n",
      "mean to -2 2018-04-01\n",
      "mean to -3 2018-03-01\n",
      "mean to -6 2017-12-01\n",
      "mean to -12 2017-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "q from: 2017-08-01\n",
      "q to: 2017-06-01\n",
      "Procesando periodo: 2018-05-01\n",
      "periodo tn_2: 2018-07-01\n",
      "Fecha ini lags: 2017-04-01\n",
      "Fecha fin lags: 2018-05-01\n",
      "mean from: 2018-04-01\n",
      "mean to -2 2018-03-01\n",
      "mean to -3 2018-02-01\n",
      "mean to -6 2017-11-01\n",
      "mean to -12 2017-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "q from: 2017-07-01\n",
      "q to: 2017-05-01\n",
      "Procesando periodo: 2018-04-01\n",
      "periodo tn_2: 2018-06-01\n",
      "Fecha ini lags: 2017-03-01\n",
      "Fecha fin lags: 2018-04-01\n",
      "mean from: 2018-03-01\n",
      "mean to -2 2018-02-01\n",
      "mean to -3 2018-01-01\n",
      "mean to -6 2017-10-01\n",
      "mean to -12 2017-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "q from: 2017-06-01\n",
      "q to: 2017-04-01\n"
     ]
    }
   ],
   "source": [
    "first_df = True\n",
    "i = 1\n",
    "for periodo in periods_to_train:\n",
    "    \n",
    "    #cada periodo\n",
    "    print(\"Procesando periodo:\", periodo)\n",
    "    \n",
    "    #tomo periodo para generar mi dataset de train\n",
    "    df_train = df[df['periodo'] == periodo]\n",
    "    \n",
    "    #========================================================================================\n",
    "    #genero el campo tn_2 target\n",
    "    #========================================================================================\n",
    "    fecha_2 = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_2 += relativedelta(months=2)  # Suma 2 meses a la fecha\n",
    "    fecha_2 = fecha_2.strftime('%Y-%m-%d')\n",
    "    print(\"periodo tn_2:\", fecha_2)\n",
    "    filtro = df['periodo'] == fecha_2\n",
    "    df_filtrado = df[filtro]\n",
    "\n",
    "    # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'tn_2'\n",
    "    df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'tn_mas_2'})\n",
    "    df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "    \n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag tn\n",
    "    #========================================================================================\n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-13)  # Suma 2 meses a la fecha\n",
    "    fecha_inicio = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha ini lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-0)  # Suma 2 meses a la fecha\n",
    "    fecha_fin = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha fin lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    fecha_inicio = pd.Timestamp(fecha_inicio)\n",
    "    fecha_fin = pd.Timestamp(fecha_fin)\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        #print('entro')\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'lag_tn_xx'\n",
    "        df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'lag_tn_'+str(lag)})\n",
    "\n",
    "\n",
    "        df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag months\n",
    "    #========================================================================================\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        #print(str(fecha.month))\n",
    "        df_train['lag_month_'+str(lag)] = str(fecha.month)\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_mean_2_3_6_12 \n",
    "    #========================================================================================\n",
    "    mean_periods = [-2,-3,-6,-12]\n",
    "    fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_from += relativedelta(months=-1)  # Suma 2 meses a la fecha\n",
    "    fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "    print(\"mean from:\", fecha_from)\n",
    "    \n",
    "    for mean_period in mean_periods:\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=mean_period)  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"mean to \"+str(mean_period) , fecha_to)\n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        df_filtrado = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado = df_filtrado.rename(columns={'tn': 'lag_tn_mean_'+str(abs(mean_period))})\n",
    "        df_train = pd.merge(df_train, df_filtrado, on='product_id', how='left')\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_sum_q1_q2_q3_q4 y lag_tn_mean_q1_q2_q3_q4\n",
    "    #========================================================================================\n",
    "    quarters = [[-1,-3], [-4,-6], [-7,-9], [-10,-12]]\n",
    "    quarters_name = ['q1', 'q2', 'q3', 'q4']\n",
    "    \n",
    "    for i in range(len(quarters)):\n",
    "        \n",
    "        fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_from += relativedelta(months=quarters[i][0])  # Suma 2 meses a la fecha\n",
    "        fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "        print(\"q from:\", fecha_from)\n",
    "\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=quarters[i][1])  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"q to:\", fecha_to)\n",
    "        \n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        #para sum\n",
    "        df_filtrado_sum = df_filtrado.groupby(['product_id']).agg({'tn': 'sum'}).reset_index()\n",
    "        df_filtrado_sum = df_filtrado_sum.rename(columns={'tn': 'lag_sum_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_sum, on='product_id', how='left')\n",
    "        #para mean\n",
    "        df_filtrado_mean = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado_mean = df_filtrado_mean.rename(columns={'tn': 'lag_mean_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_mean, on='product_id', how='left')    \n",
    "\n",
    "        \n",
    "    if first_df:\n",
    "        first_df = False\n",
    "        df_train_final = df_train\n",
    "    else:\n",
    "        df_train_final = pd.concat([df_train_final, df_train], axis=0, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a87c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Trend by quarters\n"
     ]
    }
   ],
   "source": [
    "#========================================================================================\n",
    "#genero el campo lag_trend_q1 q2 q3 q4\n",
    "#========================================================================================\n",
    "\n",
    "def calculate_trend(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2, 3], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "print(\"Columns Trend by quarters\")\n",
    "#Q1\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_2\", \"lag_tn_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q1\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q2\n",
    "column_names = [\"lag_tn_4\", \"lag_tn_5\", \"lag_tn_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q2\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q3\n",
    "column_names = [\"lag_tn_7\", \"lag_tn_8\", \"lag_tn_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q3\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q4\n",
    "column_names = [\"lag_tn_10\", \"lag_tn_11\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q4\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3390ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herna\\AppData\\Local\\Temp\\ipykernel_5832\\250140083.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train_final['tn_mas_2'] = col_T\n"
     ]
    }
   ],
   "source": [
    "# Mover la columna 'tn_mas_2' target al último lugar\n",
    "col_T = df_train_final.pop('tn_mas_2')\n",
    "df_train_final['tn_mas_2'] = col_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10199e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_mean_tn_q2</th>\n",
       "      <th>lag_sum_tn_q3</th>\n",
       "      <th>lag_mean_tn_q3</th>\n",
       "      <th>lag_sum_tn_q4</th>\n",
       "      <th>lag_mean_tn_q4</th>\n",
       "      <th>lag_trend_q1</th>\n",
       "      <th>lag_trend_q2</th>\n",
       "      <th>lag_trend_q3</th>\n",
       "      <th>lag_trend_q4</th>\n",
       "      <th>tn_mas_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20001</td>\n",
       "      <td>1647.63848</td>\n",
       "      <td>478</td>\n",
       "      <td>1757.73271</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1864.966707</td>\n",
       "      <td>4710.04632</td>\n",
       "      <td>1570.015440</td>\n",
       "      <td>3695.97419</td>\n",
       "      <td>1231.991397</td>\n",
       "      <td>-97.441510</td>\n",
       "      <td>404.255815</td>\n",
       "      <td>15.867770</td>\n",
       "      <td>50.246465</td>\n",
       "      <td>1109.93769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20002</td>\n",
       "      <td>1287.62346</td>\n",
       "      <td>454</td>\n",
       "      <td>1360.44402</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1384.918527</td>\n",
       "      <td>3093.52244</td>\n",
       "      <td>1031.174147</td>\n",
       "      <td>3136.42970</td>\n",
       "      <td>1045.476567</td>\n",
       "      <td>91.580995</td>\n",
       "      <td>184.517870</td>\n",
       "      <td>11.583320</td>\n",
       "      <td>-17.309555</td>\n",
       "      <td>928.36431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20003</td>\n",
       "      <td>565.33774</td>\n",
       "      <td>282</td>\n",
       "      <td>569.69482</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1096.696177</td>\n",
       "      <td>2524.53935</td>\n",
       "      <td>841.513117</td>\n",
       "      <td>2210.57046</td>\n",
       "      <td>736.856820</td>\n",
       "      <td>163.364545</td>\n",
       "      <td>271.756710</td>\n",
       "      <td>-128.057280</td>\n",
       "      <td>52.372575</td>\n",
       "      <td>662.38654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20004</td>\n",
       "      <td>466.70901</td>\n",
       "      <td>346</td>\n",
       "      <td>468.21007</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>732.527440</td>\n",
       "      <td>2538.70653</td>\n",
       "      <td>846.235510</td>\n",
       "      <td>1700.72775</td>\n",
       "      <td>566.909250</td>\n",
       "      <td>-54.216855</td>\n",
       "      <td>112.053045</td>\n",
       "      <td>-147.720160</td>\n",
       "      <td>81.833810</td>\n",
       "      <td>667.19411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20005</td>\n",
       "      <td>624.99880</td>\n",
       "      <td>327</td>\n",
       "      <td>629.64621</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>578.546193</td>\n",
       "      <td>2139.00521</td>\n",
       "      <td>713.001737</td>\n",
       "      <td>1681.15422</td>\n",
       "      <td>560.384740</td>\n",
       "      <td>-62.314745</td>\n",
       "      <td>260.553290</td>\n",
       "      <td>-129.717215</td>\n",
       "      <td>-25.603695</td>\n",
       "      <td>876.39696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      periodo  product_id          tn  cust_request_qty  cust_request_tn  \\\n",
       "0  2019-04-01       20001  1647.63848               478       1757.73271   \n",
       "1  2019-04-01       20002  1287.62346               454       1360.44402   \n",
       "2  2019-04-01       20003   565.33774               282        569.69482   \n",
       "3  2019-04-01       20004   466.70901               346        468.21007   \n",
       "4  2019-04-01       20005   624.99880               327        629.64621   \n",
       "\n",
       "   plan_precios_cuidados   cat1         cat2      cat3  sku_size  ...  \\\n",
       "0                      0     HC  ROPA LAVADO   Liquido    3000.0  ...   \n",
       "1                      0     HC  ROPA LAVADO   Liquido    3000.0  ...   \n",
       "2                      0  FOODS     ADEREZOS  Mayonesa     475.0  ...   \n",
       "3                      0  FOODS     ADEREZOS  Mayonesa     240.0  ...   \n",
       "4                      0  FOODS     ADEREZOS  Mayonesa     120.0  ...   \n",
       "\n",
       "   lag_mean_tn_q2  lag_sum_tn_q3  lag_mean_tn_q3  lag_sum_tn_q4  \\\n",
       "0     1864.966707     4710.04632     1570.015440     3695.97419   \n",
       "1     1384.918527     3093.52244     1031.174147     3136.42970   \n",
       "2     1096.696177     2524.53935      841.513117     2210.57046   \n",
       "3      732.527440     2538.70653      846.235510     1700.72775   \n",
       "4      578.546193     2139.00521      713.001737     1681.15422   \n",
       "\n",
       "   lag_mean_tn_q4  lag_trend_q1  lag_trend_q2  lag_trend_q3  lag_trend_q4  \\\n",
       "0     1231.991397    -97.441510    404.255815     15.867770     50.246465   \n",
       "1     1045.476567     91.580995    184.517870     11.583320    -17.309555   \n",
       "2      736.856820    163.364545    271.756710   -128.057280     52.372575   \n",
       "3      566.909250    -54.216855    112.053045   -147.720160     81.833810   \n",
       "4      560.384740    -62.314745    260.553290   -129.717215    -25.603695   \n",
       "\n",
       "     tn_mas_2  \n",
       "0  1109.93769  \n",
       "1   928.36431  \n",
       "2   662.38654  \n",
       "3   667.19411  \n",
       "4   876.39696  \n",
       "\n",
       "[5 rows x 343 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a81221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "df_train_final.to_csv(data_salida, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd296b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
