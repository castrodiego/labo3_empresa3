{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24cca832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "os.chdir(\"C:/Users/herna/OneDrive/Documentos/Labo_3/labo3_empresa3_repo/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cb6bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31243 entries, 0 to 31242\n",
      "Columns: 300 entries, periodo to cat3_delta_lag_35\n",
      "dtypes: bool(1), float64(292), int64(3), object(4)\n",
      "memory usage: 71.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#maestro de productos\n",
    "#Lea el Dataset base\n",
    "#data = \"emp3_sellout_base_period_product.csv\"\n",
    "data = \"emp3_sellout_lags_deltalags_product_categorias.csv\" #FE que dejo el NB de EMi\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "columnas_a_eliminar = ['periodo']\n",
    "df = df.drop(columnas_a_eliminar, axis=1)\n",
    "df = df.rename(columns={'periodo_fecha': 'periodo'})\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeba781",
   "metadata": {},
   "source": [
    "**setting the parametros generales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75171d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_to_train = ['2019-10-01','2019-09-01','2019-08-01','2019-07-01','2019-06-01','2019-05-01','2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01' ]\n",
    "#periods_to_train = ['2019-10-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a32a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando periodo: 2019-10-01\n",
      "periodo tn_2: 2019-12-01\n",
      "Fecha ini lags: 2018-09-01\n",
      "Fecha fin lags: 2019-10-01\n",
      "mean from: 2019-09-01\n",
      "mean to -2 2019-08-01\n",
      "mean to -3 2019-07-01\n",
      "mean to -6 2019-04-01\n",
      "mean to -12 2018-10-01\n",
      "q from: 2019-09-01\n",
      "q to: 2019-07-01\n",
      "q from: 2019-06-01\n",
      "q to: 2019-04-01\n",
      "q from: 2019-03-01\n",
      "q to: 2019-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "Procesando periodo: 2019-09-01\n",
      "periodo tn_2: 2019-11-01\n",
      "Fecha ini lags: 2018-08-01\n",
      "Fecha fin lags: 2019-09-01\n",
      "mean from: 2019-08-01\n",
      "mean to -2 2019-07-01\n",
      "mean to -3 2019-06-01\n",
      "mean to -6 2019-03-01\n",
      "mean to -12 2018-09-01\n",
      "q from: 2019-08-01\n",
      "q to: 2019-06-01\n",
      "q from: 2019-05-01\n",
      "q to: 2019-03-01\n",
      "q from: 2019-02-01\n",
      "q to: 2018-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "Procesando periodo: 2019-08-01\n",
      "periodo tn_2: 2019-10-01\n",
      "Fecha ini lags: 2018-07-01\n",
      "Fecha fin lags: 2019-08-01\n",
      "mean from: 2019-07-01\n",
      "mean to -2 2019-06-01\n",
      "mean to -3 2019-05-01\n",
      "mean to -6 2019-02-01\n",
      "mean to -12 2018-08-01\n",
      "q from: 2019-07-01\n",
      "q to: 2019-05-01\n",
      "q from: 2019-04-01\n",
      "q to: 2019-02-01\n",
      "q from: 2019-01-01\n",
      "q to: 2018-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "Procesando periodo: 2019-07-01\n",
      "periodo tn_2: 2019-09-01\n",
      "Fecha ini lags: 2018-06-01\n",
      "Fecha fin lags: 2019-07-01\n",
      "mean from: 2019-06-01\n",
      "mean to -2 2019-05-01\n",
      "mean to -3 2019-04-01\n",
      "mean to -6 2019-01-01\n",
      "mean to -12 2018-07-01\n",
      "q from: 2019-06-01\n",
      "q to: 2019-04-01\n",
      "q from: 2019-03-01\n",
      "q to: 2019-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "Procesando periodo: 2019-06-01\n",
      "periodo tn_2: 2019-08-01\n",
      "Fecha ini lags: 2018-05-01\n",
      "Fecha fin lags: 2019-06-01\n",
      "mean from: 2019-05-01\n",
      "mean to -2 2019-04-01\n",
      "mean to -3 2019-03-01\n",
      "mean to -6 2018-12-01\n",
      "mean to -12 2018-06-01\n",
      "q from: 2019-05-01\n",
      "q to: 2019-03-01\n",
      "q from: 2019-02-01\n",
      "q to: 2018-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "Procesando periodo: 2019-05-01\n",
      "periodo tn_2: 2019-07-01\n",
      "Fecha ini lags: 2018-04-01\n",
      "Fecha fin lags: 2019-05-01\n",
      "mean from: 2019-04-01\n",
      "mean to -2 2019-03-01\n",
      "mean to -3 2019-02-01\n",
      "mean to -6 2018-11-01\n",
      "mean to -12 2018-05-01\n",
      "q from: 2019-04-01\n",
      "q to: 2019-02-01\n",
      "q from: 2019-01-01\n",
      "q to: 2018-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "Procesando periodo: 2019-04-01\n",
      "periodo tn_2: 2019-06-01\n",
      "Fecha ini lags: 2018-03-01\n",
      "Fecha fin lags: 2019-04-01\n",
      "mean from: 2019-03-01\n",
      "mean to -2 2019-02-01\n",
      "mean to -3 2019-01-01\n",
      "mean to -6 2018-10-01\n",
      "mean to -12 2018-04-01\n",
      "q from: 2019-03-01\n",
      "q to: 2019-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "Procesando periodo: 2019-03-01\n",
      "periodo tn_2: 2019-05-01\n",
      "Fecha ini lags: 2018-02-01\n",
      "Fecha fin lags: 2019-03-01\n",
      "mean from: 2019-02-01\n",
      "mean to -2 2019-01-01\n",
      "mean to -3 2018-12-01\n",
      "mean to -6 2018-09-01\n",
      "mean to -12 2018-03-01\n",
      "q from: 2019-02-01\n",
      "q to: 2018-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "Procesando periodo: 2019-02-01\n",
      "periodo tn_2: 2019-04-01\n",
      "Fecha ini lags: 2018-01-01\n",
      "Fecha fin lags: 2019-02-01\n",
      "mean from: 2019-01-01\n",
      "mean to -2 2018-12-01\n",
      "mean to -3 2018-11-01\n",
      "mean to -6 2018-08-01\n",
      "mean to -12 2018-02-01\n",
      "q from: 2019-01-01\n",
      "q to: 2018-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "Procesando periodo: 2019-01-01\n",
      "periodo tn_2: 2019-03-01\n",
      "Fecha ini lags: 2017-12-01\n",
      "Fecha fin lags: 2019-01-01\n",
      "mean from: 2018-12-01\n",
      "mean to -2 2018-11-01\n",
      "mean to -3 2018-10-01\n",
      "mean to -6 2018-07-01\n",
      "mean to -12 2018-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "Procesando periodo: 2018-12-01\n",
      "periodo tn_2: 2019-02-01\n",
      "Fecha ini lags: 2017-11-01\n",
      "Fecha fin lags: 2018-12-01\n",
      "mean from: 2018-11-01\n",
      "mean to -2 2018-10-01\n",
      "mean to -3 2018-09-01\n",
      "mean to -6 2018-06-01\n",
      "mean to -12 2017-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "Procesando periodo: 2018-11-01\n",
      "periodo tn_2: 2019-01-01\n",
      "Fecha ini lags: 2017-10-01\n",
      "Fecha fin lags: 2018-11-01\n",
      "mean from: 2018-10-01\n",
      "mean to -2 2018-09-01\n",
      "mean to -3 2018-08-01\n",
      "mean to -6 2018-05-01\n",
      "mean to -12 2017-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n"
     ]
    }
   ],
   "source": [
    "first_df = True\n",
    "i = 1\n",
    "for periodo in periods_to_train:\n",
    "    \n",
    "    #cada periodo\n",
    "    print(\"Procesando periodo:\", periodo)\n",
    "    \n",
    "    #tomo periodo para generar mi dataset de train\n",
    "    df_train = df[df['periodo'] == periodo]\n",
    "    \n",
    "    #========================================================================================\n",
    "    #genero el campo tn_2 target\n",
    "    #========================================================================================\n",
    "    fecha_2 = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_2 += relativedelta(months=2)  # Suma 2 meses a la fecha\n",
    "    fecha_2 = fecha_2.strftime('%Y-%m-%d')\n",
    "    print(\"periodo tn_2:\", fecha_2)\n",
    "    filtro = df['periodo'] == fecha_2\n",
    "    df_filtrado = df[filtro]\n",
    "\n",
    "    # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'tn_2'\n",
    "    df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'tn_mas_2'})\n",
    "    df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "    \n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag tn\n",
    "    #========================================================================================\n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-13)  # Suma 2 meses a la fecha\n",
    "    fecha_inicio = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha ini lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-0)  # Suma 2 meses a la fecha\n",
    "    fecha_fin = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha fin lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    fecha_inicio = pd.Timestamp(fecha_inicio)\n",
    "    fecha_fin = pd.Timestamp(fecha_fin)\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        #print('entro')\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'lag_tn_xx'\n",
    "        df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'lag_tn_'+str(lag)})\n",
    "\n",
    "\n",
    "        df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag months\n",
    "    #========================================================================================\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        #print(str(fecha.month))\n",
    "        df_train['lag_month_'+str(lag)] = str(fecha.month)\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_mean_2_3_6_12 \n",
    "    #========================================================================================\n",
    "    mean_periods = [-2,-3,-6,-12]\n",
    "    fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_from += relativedelta(months=-1)  # Suma 2 meses a la fecha\n",
    "    fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "    print(\"mean from:\", fecha_from)\n",
    "    \n",
    "    for mean_period in mean_periods:\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=mean_period)  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"mean to \"+str(mean_period) , fecha_to)\n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        df_filtrado = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado = df_filtrado.rename(columns={'tn': 'lag_tn_mean_'+str(abs(mean_period))})\n",
    "        df_train = pd.merge(df_train, df_filtrado, on='product_id', how='left')\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_sum_q1_q2_q3_q4 y lag_tn_mean_q1_q2_q3_q4\n",
    "    #========================================================================================\n",
    "    quarters = [[-1,-3], [-4,-6], [-7,-9], [-10,-12]]\n",
    "    quarters_name = ['q1', 'q2', 'q3', 'q4']\n",
    "    \n",
    "    for i in range(len(quarters)):\n",
    "        \n",
    "        fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_from += relativedelta(months=quarters[i][0])  # Suma 2 meses a la fecha\n",
    "        fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "        print(\"q from:\", fecha_from)\n",
    "\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=quarters[i][1])  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"q to:\", fecha_to)\n",
    "        \n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        #para sum\n",
    "        df_filtrado_sum = df_filtrado.groupby(['product_id']).agg({'tn': 'sum'}).reset_index()\n",
    "        df_filtrado_sum = df_filtrado_sum.rename(columns={'tn': 'lag_sum_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_sum, on='product_id', how='left')\n",
    "        #para mean\n",
    "        df_filtrado_mean = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado_mean = df_filtrado_mean.rename(columns={'tn': 'lag_mean_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_mean, on='product_id', how='left')    \n",
    "\n",
    "        \n",
    "    if first_df:\n",
    "        first_df = False\n",
    "        df_train_final = df_train\n",
    "    else:\n",
    "        df_train_final = pd.concat([df_train_final, df_train], axis=0, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2a87c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Trend by quarters\n"
     ]
    }
   ],
   "source": [
    "#========================================================================================\n",
    "#genero el campo lag_trend_q1 q2 q3 q4\n",
    "#========================================================================================\n",
    "\n",
    "def calculate_trend(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2, 3], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "print(\"Columns Trend by quarters\")\n",
    "#Q1\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_2\", \"lag_tn_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q1\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q2\n",
    "column_names = [\"lag_tn_4\", \"lag_tn_5\", \"lag_tn_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q2\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q3\n",
    "column_names = [\"lag_tn_7\", \"lag_tn_8\", \"lag_tn_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q3\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q4\n",
    "column_names = [\"lag_tn_10\", \"lag_tn_11\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q4\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10199e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_sum_tn_q2</th>\n",
       "      <th>lag_mean_tn_q2</th>\n",
       "      <th>lag_sum_tn_q3</th>\n",
       "      <th>lag_mean_tn_q3</th>\n",
       "      <th>lag_sum_tn_q4</th>\n",
       "      <th>lag_mean_tn_q4</th>\n",
       "      <th>lag_trend_q1</th>\n",
       "      <th>lag_trend_q2</th>\n",
       "      <th>lag_trend_q3</th>\n",
       "      <th>lag_trend_q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>20001</td>\n",
       "      <td>1561.50552</td>\n",
       "      <td>367</td>\n",
       "      <td>1587.87525</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4387.35850</td>\n",
       "      <td>1462.452833</td>\n",
       "      <td>4005.52367</td>\n",
       "      <td>1335.174557</td>\n",
       "      <td>5594.90012</td>\n",
       "      <td>1864.966707</td>\n",
       "      <td>9.493785</td>\n",
       "      <td>268.850395</td>\n",
       "      <td>-97.441510</td>\n",
       "      <td>404.255815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>20002</td>\n",
       "      <td>1979.53635</td>\n",
       "      <td>312</td>\n",
       "      <td>2013.36305</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3250.97704</td>\n",
       "      <td>1083.659013</td>\n",
       "      <td>3393.42652</td>\n",
       "      <td>1131.142173</td>\n",
       "      <td>4154.75558</td>\n",
       "      <td>1384.918527</td>\n",
       "      <td>-11.868860</td>\n",
       "      <td>179.629575</td>\n",
       "      <td>91.580995</td>\n",
       "      <td>184.517870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>20003</td>\n",
       "      <td>1081.36645</td>\n",
       "      <td>404</td>\n",
       "      <td>1091.94793</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1817.84943</td>\n",
       "      <td>605.949810</td>\n",
       "      <td>2361.13586</td>\n",
       "      <td>787.045287</td>\n",
       "      <td>3290.08853</td>\n",
       "      <td>1096.696177</td>\n",
       "      <td>-126.284010</td>\n",
       "      <td>-48.524400</td>\n",
       "      <td>163.364545</td>\n",
       "      <td>271.756710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>20004</td>\n",
       "      <td>1064.69633</td>\n",
       "      <td>508</td>\n",
       "      <td>1078.32756</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1737.21393</td>\n",
       "      <td>579.071310</td>\n",
       "      <td>1572.81129</td>\n",
       "      <td>524.270430</td>\n",
       "      <td>2197.58232</td>\n",
       "      <td>732.527440</td>\n",
       "      <td>-132.228105</td>\n",
       "      <td>-100.242550</td>\n",
       "      <td>-54.216855</td>\n",
       "      <td>112.053045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>20005</td>\n",
       "      <td>996.78275</td>\n",
       "      <td>418</td>\n",
       "      <td>1040.72694</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2398.65873</td>\n",
       "      <td>799.552910</td>\n",
       "      <td>1261.69775</td>\n",
       "      <td>420.565917</td>\n",
       "      <td>1735.63858</td>\n",
       "      <td>578.546193</td>\n",
       "      <td>-66.889150</td>\n",
       "      <td>-125.699080</td>\n",
       "      <td>-62.314745</td>\n",
       "      <td>260.553290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      periodo  product_id          tn  cust_request_qty  cust_request_tn  \\\n",
       "0  2019-10-01       20001  1561.50552               367       1587.87525   \n",
       "1  2019-10-01       20002  1979.53635               312       2013.36305   \n",
       "2  2019-10-01       20003  1081.36645               404       1091.94793   \n",
       "3  2019-10-01       20004  1064.69633               508       1078.32756   \n",
       "4  2019-10-01       20005   996.78275               418       1040.72694   \n",
       "\n",
       "   plan_precios_cuidados   cat1         cat2      cat3  sku_size  ...  \\\n",
       "0                      0     HC  ROPA LAVADO   Liquido    3000.0  ...   \n",
       "1                      0     HC  ROPA LAVADO   Liquido    3000.0  ...   \n",
       "2                      0  FOODS     ADEREZOS  Mayonesa     475.0  ...   \n",
       "3                      0  FOODS     ADEREZOS  Mayonesa     240.0  ...   \n",
       "4                      0  FOODS     ADEREZOS  Mayonesa     120.0  ...   \n",
       "\n",
       "   lag_sum_tn_q2  lag_mean_tn_q2  lag_sum_tn_q3  lag_mean_tn_q3  \\\n",
       "0     4387.35850     1462.452833     4005.52367     1335.174557   \n",
       "1     3250.97704     1083.659013     3393.42652     1131.142173   \n",
       "2     1817.84943      605.949810     2361.13586      787.045287   \n",
       "3     1737.21393      579.071310     1572.81129      524.270430   \n",
       "4     2398.65873      799.552910     1261.69775      420.565917   \n",
       "\n",
       "   lag_sum_tn_q4  lag_mean_tn_q4  lag_trend_q1  lag_trend_q2  lag_trend_q3  \\\n",
       "0     5594.90012     1864.966707      9.493785    268.850395    -97.441510   \n",
       "1     4154.75558     1384.918527    -11.868860    179.629575     91.580995   \n",
       "2     3290.08853     1096.696177   -126.284010    -48.524400    163.364545   \n",
       "3     2197.58232      732.527440   -132.228105   -100.242550    -54.216855   \n",
       "4     1735.63858      578.546193    -66.889150   -125.699080    -62.314745   \n",
       "\n",
       "   lag_trend_q4  \n",
       "0    404.255815  \n",
       "1    184.517870  \n",
       "2    271.756710  \n",
       "3    112.053045  \n",
       "4    260.553290  \n",
       "\n",
       "[5 rows x 343 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90a81221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "df_train_final.to_csv(r'C:\\Users\\herna\\OneDrive\\Documentos\\Labo_3\\labo3_empresa3_repo\\datasets\\emp3_sellout_base_period_product_FE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd296b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
