{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cca832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "####################################################\n",
    "############# Setear segun cada maquina ############\n",
    "os.chdir(\"C:/Users/herna/labo3_empresa3_repo/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2dd467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File in: emp3_sellout_lags_deltalags_product_categorias_sin_norm.csv\n",
      "File out: emp3_sellout_base_period_product_FE_sin_norm.csv\n"
     ]
    }
   ],
   "source": [
    "#selecciono que archivo procesar segun el tipo de transformacion a tilizar\n",
    "#//sin_norm=sin normalizacion //cero_uno=min max (0-1) //media_sd=standard media y desvio\n",
    "tipos_norm = ['sin_norm', 'cero_uno', 'media_sd']\n",
    "\n",
    "normalizacion = tipos_norm[0] \n",
    "\n",
    "#data = \"emp3_sellout_base_period_product.csv\"\n",
    "data_entrada = \"emp3_sellout_lags_deltalags_product_categorias\" #FE que dejo el NB de EMi BASE\n",
    "data_salida = \"emp3_sellout_base_period_product_FE\"\n",
    "\n",
    "if normalizacion == tipos_norm[0]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n",
    "    \n",
    "elif normalizacion == tipos_norm[1]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n",
    "    \n",
    "elif normalizacion == tipos_norm[2]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb6bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31243 entries, 0 to 31242\n",
      "Columns: 300 entries, periodo to cat3_delta_lag_35\n",
      "dtypes: bool(1), float64(292), int64(3), object(4)\n",
      "memory usage: 71.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Lea el Dataset base\n",
    "df = pd.read_csv(data_entrada)\n",
    "\n",
    "columnas_a_eliminar = ['periodo']\n",
    "df = df.drop(columnas_a_eliminar, axis=1)\n",
    "df = df.rename(columns={'periodo_fecha': 'periodo'})\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeba781",
   "metadata": {},
   "source": [
    "**setting the parametros generales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75171d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#periods_to_train = ['2019-10-01','2019-09-01','2019-08-01','2019-07-01','2019-06-01','2019-05-01','2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01' ]\n",
    "#periods_to_train = ['2019-10-01']\n",
    "#de Abril 2019 y 13 meses hacia atras\n",
    "periods_to_train = ['2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01','2018-10-01',\n",
    "                    '2018-09-01','2018-08-01','2018-07-01','2018-06-01','2018-05-01','2018-04-01','2018-03-01',\n",
    "                    '2018-02-01','2018-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a32a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando periodo: 2019-04-01\n",
      "periodo tn_2: 2019-06-01\n",
      "Fecha ini lags: 2018-03-01\n",
      "Fecha fin lags: 2019-04-01\n",
      "mean from: 2019-03-01\n",
      "mean to -2 2019-02-01\n",
      "mean to -3 2019-01-01\n",
      "mean to -6 2018-10-01\n",
      "mean to -12 2018-04-01\n",
      "q from: 2019-03-01\n",
      "q to: 2019-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "Procesando periodo: 2019-03-01\n",
      "periodo tn_2: 2019-05-01\n",
      "Fecha ini lags: 2018-02-01\n",
      "Fecha fin lags: 2019-03-01\n",
      "mean from: 2019-02-01\n",
      "mean to -2 2019-01-01\n",
      "mean to -3 2018-12-01\n",
      "mean to -6 2018-09-01\n",
      "mean to -12 2018-03-01\n",
      "q from: 2019-02-01\n",
      "q to: 2018-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "Procesando periodo: 2019-02-01\n",
      "periodo tn_2: 2019-04-01\n",
      "Fecha ini lags: 2018-01-01\n",
      "Fecha fin lags: 2019-02-01\n",
      "mean from: 2019-01-01\n",
      "mean to -2 2018-12-01\n",
      "mean to -3 2018-11-01\n",
      "mean to -6 2018-08-01\n",
      "mean to -12 2018-02-01\n",
      "q from: 2019-01-01\n",
      "q to: 2018-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "Procesando periodo: 2019-01-01\n",
      "periodo tn_2: 2019-03-01\n",
      "Fecha ini lags: 2017-12-01\n",
      "Fecha fin lags: 2019-01-01\n",
      "mean from: 2018-12-01\n",
      "mean to -2 2018-11-01\n",
      "mean to -3 2018-10-01\n",
      "mean to -6 2018-07-01\n",
      "mean to -12 2018-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "Procesando periodo: 2018-12-01\n",
      "periodo tn_2: 2019-02-01\n",
      "Fecha ini lags: 2017-11-01\n",
      "Fecha fin lags: 2018-12-01\n",
      "mean from: 2018-11-01\n",
      "mean to -2 2018-10-01\n",
      "mean to -3 2018-09-01\n",
      "mean to -6 2018-06-01\n",
      "mean to -12 2017-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "Procesando periodo: 2018-11-01\n",
      "periodo tn_2: 2019-01-01\n",
      "Fecha ini lags: 2017-10-01\n",
      "Fecha fin lags: 2018-11-01\n",
      "mean from: 2018-10-01\n",
      "mean to -2 2018-09-01\n",
      "mean to -3 2018-08-01\n",
      "mean to -6 2018-05-01\n",
      "mean to -12 2017-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "Procesando periodo: 2018-10-01\n",
      "periodo tn_2: 2018-12-01\n",
      "Fecha ini lags: 2017-09-01\n",
      "Fecha fin lags: 2018-10-01\n",
      "mean from: 2018-09-01\n",
      "mean to -2 2018-08-01\n",
      "mean to -3 2018-07-01\n",
      "mean to -6 2018-04-01\n",
      "mean to -12 2017-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "Procesando periodo: 2018-09-01\n",
      "periodo tn_2: 2018-11-01\n",
      "Fecha ini lags: 2017-08-01\n",
      "Fecha fin lags: 2018-09-01\n",
      "mean from: 2018-08-01\n",
      "mean to -2 2018-07-01\n",
      "mean to -3 2018-06-01\n",
      "mean to -6 2018-03-01\n",
      "mean to -12 2017-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "Procesando periodo: 2018-08-01\n",
      "periodo tn_2: 2018-10-01\n",
      "Fecha ini lags: 2017-07-01\n",
      "Fecha fin lags: 2018-08-01\n",
      "mean from: 2018-07-01\n",
      "mean to -2 2018-06-01\n",
      "mean to -3 2018-05-01\n",
      "mean to -6 2018-02-01\n",
      "mean to -12 2017-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "Procesando periodo: 2018-07-01\n",
      "periodo tn_2: 2018-09-01\n",
      "Fecha ini lags: 2017-06-01\n",
      "Fecha fin lags: 2018-07-01\n",
      "mean from: 2018-06-01\n",
      "mean to -2 2018-05-01\n",
      "mean to -3 2018-04-01\n",
      "mean to -6 2018-01-01\n",
      "mean to -12 2017-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "Procesando periodo: 2018-06-01\n",
      "periodo tn_2: 2018-08-01\n",
      "Fecha ini lags: 2017-05-01\n",
      "Fecha fin lags: 2018-06-01\n",
      "mean from: 2018-05-01\n",
      "mean to -2 2018-04-01\n",
      "mean to -3 2018-03-01\n",
      "mean to -6 2017-12-01\n",
      "mean to -12 2017-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "q from: 2017-08-01\n",
      "q to: 2017-06-01\n",
      "Procesando periodo: 2018-05-01\n",
      "periodo tn_2: 2018-07-01\n",
      "Fecha ini lags: 2017-04-01\n",
      "Fecha fin lags: 2018-05-01\n",
      "mean from: 2018-04-01\n",
      "mean to -2 2018-03-01\n",
      "mean to -3 2018-02-01\n",
      "mean to -6 2017-11-01\n",
      "mean to -12 2017-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "q from: 2017-07-01\n",
      "q to: 2017-05-01\n",
      "Procesando periodo: 2018-04-01\n",
      "periodo tn_2: 2018-06-01\n",
      "Fecha ini lags: 2017-03-01\n",
      "Fecha fin lags: 2018-04-01\n",
      "mean from: 2018-03-01\n",
      "mean to -2 2018-02-01\n",
      "mean to -3 2018-01-01\n",
      "mean to -6 2017-10-01\n",
      "mean to -12 2017-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "q from: 2017-06-01\n",
      "q to: 2017-04-01\n",
      "Procesando periodo: 2018-03-01\n",
      "periodo tn_2: 2018-05-01\n",
      "Fecha ini lags: 2017-02-01\n",
      "Fecha fin lags: 2018-03-01\n",
      "mean from: 2018-02-01\n",
      "mean to -2 2018-01-01\n",
      "mean to -3 2017-12-01\n",
      "mean to -6 2017-09-01\n",
      "mean to -12 2017-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "q from: 2017-08-01\n",
      "q to: 2017-06-01\n",
      "q from: 2017-05-01\n",
      "q to: 2017-03-01\n",
      "Procesando periodo: 2018-02-01\n",
      "periodo tn_2: 2018-04-01\n",
      "Fecha ini lags: 2017-01-01\n",
      "Fecha fin lags: 2018-02-01\n",
      "mean from: 2018-01-01\n",
      "mean to -2 2017-12-01\n",
      "mean to -3 2017-11-01\n",
      "mean to -6 2017-08-01\n",
      "mean to -12 2017-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "q from: 2017-07-01\n",
      "q to: 2017-05-01\n",
      "q from: 2017-04-01\n",
      "q to: 2017-02-01\n",
      "Procesando periodo: 2018-01-01\n",
      "periodo tn_2: 2018-03-01\n",
      "Fecha ini lags: 2016-12-01\n",
      "Fecha fin lags: 2018-01-01\n",
      "mean from: 2017-12-01\n",
      "mean to -2 2017-11-01\n",
      "mean to -3 2017-10-01\n",
      "mean to -6 2017-07-01\n",
      "mean to -12 2017-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "q from: 2017-06-01\n",
      "q to: 2017-04-01\n",
      "q from: 2017-03-01\n",
      "q to: 2017-01-01\n"
     ]
    }
   ],
   "source": [
    "first_df = True\n",
    "i = 1\n",
    "for periodo in periods_to_train:\n",
    "    \n",
    "    #cada periodo\n",
    "    print(\"Procesando periodo:\", periodo)\n",
    "    \n",
    "    #tomo periodo para generar mi dataset de train\n",
    "    df_train = df[df['periodo'] == periodo]\n",
    "    \n",
    "    #========================================================================================\n",
    "    #genero el campo tn_2 target\n",
    "    #========================================================================================\n",
    "    fecha_2 = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_2 += relativedelta(months=2)  # Suma 2 meses a la fecha\n",
    "    fecha_2 = fecha_2.strftime('%Y-%m-%d')\n",
    "    print(\"periodo tn_2:\", fecha_2)\n",
    "    filtro = df['periodo'] == fecha_2\n",
    "    df_filtrado = df[filtro]\n",
    "\n",
    "    # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'tn_2'\n",
    "    df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'tn_mas_2'})\n",
    "    df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "    \n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag tn\n",
    "    #========================================================================================\n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-13)  # Suma 2 meses a la fecha\n",
    "    fecha_inicio = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha ini lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-0)  # Suma 2 meses a la fecha\n",
    "    fecha_fin = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha fin lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    fecha_inicio = pd.Timestamp(fecha_inicio)\n",
    "    fecha_fin = pd.Timestamp(fecha_fin)\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        #print('entro')\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'lag_tn_xx'\n",
    "        df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'lag_tn_'+str(lag)})\n",
    "\n",
    "\n",
    "        df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag months\n",
    "    #========================================================================================\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        #print(str(fecha.month))\n",
    "        df_train['lag_month_'+str(lag)] = str(fecha.month)\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_mean_2_3_6_12 \n",
    "    #========================================================================================\n",
    "    mean_periods = [-2,-3,-6,-12]\n",
    "    fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_from += relativedelta(months=-1)  # Suma 2 meses a la fecha\n",
    "    fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "    print(\"mean from:\", fecha_from)\n",
    "    \n",
    "    for mean_period in mean_periods:\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=mean_period)  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"mean to \"+str(mean_period) , fecha_to)\n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        df_filtrado = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado = df_filtrado.rename(columns={'tn': 'lag_tn_mean_'+str(abs(mean_period))})\n",
    "        df_train = pd.merge(df_train, df_filtrado, on='product_id', how='left')\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_sum_q1_q2_q3_q4 y lag_tn_mean_q1_q2_q3_q4\n",
    "    #========================================================================================\n",
    "    quarters = [[-1,-3], [-4,-6], [-7,-9], [-10,-12]]\n",
    "    quarters_name = ['q1', 'q2', 'q3', 'q4']\n",
    "    \n",
    "    for i in range(len(quarters)):\n",
    "        \n",
    "        fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_from += relativedelta(months=quarters[i][0])  # Suma 2 meses a la fecha\n",
    "        fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "        print(\"q from:\", fecha_from)\n",
    "\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=quarters[i][1])  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"q to:\", fecha_to)\n",
    "        \n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        #para sum\n",
    "        df_filtrado_sum = df_filtrado.groupby(['product_id']).agg({'tn': 'sum'}).reset_index()\n",
    "        df_filtrado_sum = df_filtrado_sum.rename(columns={'tn': 'lag_sum_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_sum, on='product_id', how='left')\n",
    "        #para mean\n",
    "        df_filtrado_mean = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado_mean = df_filtrado_mean.rename(columns={'tn': 'lag_mean_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_mean, on='product_id', how='left')    \n",
    "\n",
    "        \n",
    "    if first_df:\n",
    "        first_df = False\n",
    "        df_train_final = df_train\n",
    "    else:\n",
    "        df_train_final = pd.concat([df_train_final, df_train], axis=0, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a87c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Trend by 2 months\n",
      "Columns Trend by quarters\n",
      "Columns Trend by half year\n"
     ]
    }
   ],
   "source": [
    "#========================================================================================\n",
    "#genero el campo lag_trend_q1 q2 q3 q4\n",
    "#========================================================================================\n",
    "\n",
    "def calculate_trend_2(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def calculate_trend(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2, 3], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def calculate_trend_4(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2, 3, 4], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "def calculate_trend_6(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2, 3, 4, 5, 6], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "print(\"Columns Trend by 2 months\")\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_2\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_1_2\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_2\", \"lag_tn_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_2_3\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_3\", \"lag_tn_4\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_3_4\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_4\", \"lag_tn_5\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_4_5\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_5\", \"lag_tn_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_5_6\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_6\", \"lag_tn_7\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_6_7\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_7\", \"lag_tn_8\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_7_8\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_8\", \"lag_tn_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_8_9\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_9\", \"lag_tn_10\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_9_10\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_10\", \"lag_tn_11\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_10_11\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_11\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_11_12\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_1_13\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"tn\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_0_12\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"tn\", \"lag_tn_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_0_13\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"tn\", \"lag_tn_1\", \"lag_tn_12\",\"lag_tn_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_0_1_12_13\"] = df_train_final.apply(calculate_trend_4, args=column_names, axis=1).copy()\n",
    "\n",
    "\n",
    "print(\"Columns Trend by quarters\")\n",
    "#Q1\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_2\", \"lag_tn_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q1\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q2\n",
    "column_names = [\"lag_tn_4\", \"lag_tn_5\", \"lag_tn_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q2\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q3\n",
    "column_names = [\"lag_tn_7\", \"lag_tn_8\", \"lag_tn_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q3\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q4\n",
    "column_names = [\"lag_tn_10\", \"lag_tn_11\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q4\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "print(\"Columns Trend by half year\")\n",
    "#first_6_months\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_2\", \"lag_tn_3\", \"lag_tn_4\", \"lag_tn_5\", \"lag_tn_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_first_6m\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n",
    "#second_6_months\n",
    "column_names = [\"lag_tn_7\", \"lag_tn_8\", \"lag_tn_9\",\"lag_tn_10\", \"lag_tn_11\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_second_6m\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n",
    "\n",
    "#second_6_months\n",
    "column_names = [\"tn\", \"lag_tn_1\", \"lag_tn_2\",\"lag_tn_11\", \"lag_tn_12\", \"lag_tn_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q1_q4\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71214ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Trend by quarters Cat3\n",
      "Columns Trend by half year\n"
     ]
    }
   ],
   "source": [
    "#========================================================================================\n",
    "#genero el campo lag_trend_q1 q2 q3 q4 by Cat3\n",
    "#========================================================================================\n",
    "\n",
    "column_names = [\"cat3_lag_1\", \"cat3_lag_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_1_12\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"cat3_lag_2\", \"cat3_lag_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_2_13\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "print(\"Columns Trend by quarters Cat3\")\n",
    "#Q1\n",
    "column_names = [\"cat3_lag_1\", \"cat3_lag_2\", \"cat3_lag_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_q1\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q2\n",
    "column_names = [\"cat3_lag_4\", \"cat3_lag_5\", \"cat3_lag_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_q2\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q3\n",
    "column_names = [\"cat3_lag_7\", \"cat3_lag_8\", \"cat3_lag_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_q3\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q4\n",
    "column_names = [\"cat3_lag_10\", \"cat3_lag_11\", \"cat3_lag_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_q4\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "print(\"Columns Trend by half year cat3\")\n",
    "#first_6_months\n",
    "column_names = [\"cat3_lag_1\", \"cat3_lag_2\", \"cat3_lag_3\", \"cat3_lag_4\", \"cat3_lag_5\", \"cat3_lag_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_first_6m\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n",
    "#second_6_months\n",
    "column_names = [\"cat3_lag_7\", \"cat3_lag_8\", \"cat3_lag_9\",\"cat3_lag_10\", \"cat3_lag_11\", \"cat3_lag_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_second_6m\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n",
    "\n",
    "#second_6_months\n",
    "column_names = [\"tn\", \"cat3_lag_1\", \"cat3_lag_2\",\"cat3_lag_11\", \"cat3_lag_12\", \"cat3_lag_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat3_lag_trend_q1_q4\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0ed7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Trend by quarters cat1\n",
      "Columns Trend by half year\n"
     ]
    }
   ],
   "source": [
    "#========================================================================================\n",
    "#genero el campo lag_trend_q1 q2 q3 q4 by cat1\n",
    "#========================================================================================\n",
    "\n",
    "column_names = [\"cat1_lag_1\", \"cat1_lag_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_1_12\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "column_names = [\"cat1_lag_2\", \"cat1_lag_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_2_13\"] = df_train_final.apply(calculate_trend_2, args=column_names, axis=1).copy()\n",
    "\n",
    "print(\"Columns Trend by quarters cat1\")\n",
    "#Q1\n",
    "column_names = [\"cat1_lag_1\", \"cat1_lag_2\", \"cat1_lag_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_q1\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q2\n",
    "column_names = [\"cat1_lag_4\", \"cat1_lag_5\", \"cat1_lag_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_q2\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q3\n",
    "column_names = [\"cat1_lag_7\", \"cat1_lag_8\", \"cat1_lag_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_q3\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q4\n",
    "column_names = [\"cat1_lag_10\", \"cat1_lag_11\", \"cat1_lag_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_q4\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "print(\"Columns Trend by half year cat1\")\n",
    "#first_6_months\n",
    "column_names = [\"cat1_lag_1\", \"cat1_lag_2\", \"cat1_lag_3\", \"cat1_lag_4\", \"cat1_lag_5\", \"cat1_lag_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_first_6m\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n",
    "#second_6_months\n",
    "column_names = [\"cat1_lag_7\", \"cat1_lag_8\", \"cat1_lag_9\",\"cat1_lag_10\", \"cat1_lag_11\", \"cat1_lag_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_second_6m\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()\n",
    "\n",
    "#second_6_months\n",
    "column_names = [\"tn\", \"cat1_lag_1\", \"cat1_lag_2\",\"cat1_lag_11\", \"cat1_lag_12\", \"cat1_lag_13\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"cat1_lag_trend_q1_q4\"] = df_train_final.apply(calculate_trend_6, args=column_names, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3390ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herna\\AppData\\Local\\Temp\\ipykernel_31388\\250140083.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train_final['tn_mas_2'] = col_T\n"
     ]
    }
   ],
   "source": [
    "# Mover la columna 'tn_mas_2' target al último lugar\n",
    "col_T = df_train_final.pop('tn_mas_2')\n",
    "df_train_final['tn_mas_2'] = col_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10199e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>...</th>\n",
       "      <th>cat1_lag_trend_1_12</th>\n",
       "      <th>cat1_lag_trend_2_13</th>\n",
       "      <th>cat1_lag_trend_q1</th>\n",
       "      <th>cat1_lag_trend_q2</th>\n",
       "      <th>cat1_lag_trend_q3</th>\n",
       "      <th>cat1_lag_trend_q4</th>\n",
       "      <th>cat1_lag_trend_first_6m</th>\n",
       "      <th>cat1_lag_trend_second_6m</th>\n",
       "      <th>cat1_lag_trend_q1_q4</th>\n",
       "      <th>tn_mas_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20001</td>\n",
       "      <td>1647.63848</td>\n",
       "      <td>478</td>\n",
       "      <td>1757.73271</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66026</td>\n",
       "      <td>0.62324</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.138355</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>-0.153595</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>-0.132947</td>\n",
       "      <td>-235.168102</td>\n",
       "      <td>1109.93769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20002</td>\n",
       "      <td>1287.62346</td>\n",
       "      <td>454</td>\n",
       "      <td>1360.44402</td>\n",
       "      <td>0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1646.46403</td>\n",
       "      <td>0.66026</td>\n",
       "      <td>-823.689565</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.040570</td>\n",
       "      <td>-0.440950</td>\n",
       "      <td>-235.337091</td>\n",
       "      <td>0.066189</td>\n",
       "      <td>-324.912208</td>\n",
       "      <td>928.36431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20003</td>\n",
       "      <td>565.33774</td>\n",
       "      <td>282</td>\n",
       "      <td>569.69482</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>475.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16216</td>\n",
       "      <td>0.13501</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.066915</td>\n",
       "      <td>-0.021095</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>-80.725028</td>\n",
       "      <td>662.38654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20004</td>\n",
       "      <td>466.70901</td>\n",
       "      <td>346</td>\n",
       "      <td>468.21007</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-565.19400</td>\n",
       "      <td>0.16216</td>\n",
       "      <td>-282.667940</td>\n",
       "      <td>0.034275</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>0.040920</td>\n",
       "      <td>-80.749827</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>-115.087741</td>\n",
       "      <td>667.19411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>20005</td>\n",
       "      <td>624.99880</td>\n",
       "      <td>327</td>\n",
       "      <td>629.64621</td>\n",
       "      <td>0</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>Mayonesa</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-466.49647</td>\n",
       "      <td>-565.19400</td>\n",
       "      <td>-233.350410</td>\n",
       "      <td>0.007485</td>\n",
       "      <td>0.057095</td>\n",
       "      <td>0.068235</td>\n",
       "      <td>-115.126899</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>-145.401159</td>\n",
       "      <td>876.39696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      periodo  product_id          tn  cust_request_qty  cust_request_tn  \\\n",
       "0  2019-04-01       20001  1647.63848               478       1757.73271   \n",
       "1  2019-04-01       20002  1287.62346               454       1360.44402   \n",
       "2  2019-04-01       20003   565.33774               282        569.69482   \n",
       "3  2019-04-01       20004   466.70901               346        468.21007   \n",
       "4  2019-04-01       20005   624.99880               327        629.64621   \n",
       "\n",
       "   plan_precios_cuidados   cat1         cat2      cat3  sku_size  ...  \\\n",
       "0                      0     HC  ROPA LAVADO   Liquido    3000.0  ...   \n",
       "1                      0     HC  ROPA LAVADO   Liquido    3000.0  ...   \n",
       "2                      0  FOODS     ADEREZOS  Mayonesa     475.0  ...   \n",
       "3                      0  FOODS     ADEREZOS  Mayonesa     240.0  ...   \n",
       "4                      0  FOODS     ADEREZOS  Mayonesa     120.0  ...   \n",
       "\n",
       "   cat1_lag_trend_1_12  cat1_lag_trend_2_13  cat1_lag_trend_q1  \\\n",
       "0              0.66026              0.62324           0.002515   \n",
       "1          -1646.46403              0.66026        -823.689565   \n",
       "2              0.16216              0.13501           0.002400   \n",
       "3           -565.19400              0.16216        -282.667940   \n",
       "4           -466.49647           -565.19400        -233.350410   \n",
       "\n",
       "   cat1_lag_trend_q2  cat1_lag_trend_q3  cat1_lag_trend_q4  \\\n",
       "0           0.138355           0.012330          -0.153595   \n",
       "1           0.010245           0.040570          -0.440950   \n",
       "2           0.008870          -0.066915          -0.021095   \n",
       "3           0.034275           0.020750           0.040920   \n",
       "4           0.007485           0.057095           0.068235   \n",
       "\n",
       "   cat1_lag_trend_first_6m  cat1_lag_trend_second_6m  cat1_lag_trend_q1_q4  \\\n",
       "0                 0.038711                 -0.132947           -235.168102   \n",
       "1              -235.337091                  0.066189           -324.912208   \n",
       "2                 0.010708                  0.006479            -80.725028   \n",
       "3               -80.749827                  0.016632           -115.087741   \n",
       "4              -115.126899                  0.017638           -145.401159   \n",
       "\n",
       "     tn_mas_2  \n",
       "0  1109.93769  \n",
       "1   928.36431  \n",
       "2   662.38654  \n",
       "3   667.19411  \n",
       "4   876.39696  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a81221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "df_train_final.to_csv(data_salida, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd296b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
