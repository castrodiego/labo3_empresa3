{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cca832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3cb5ce-2fe1-49dd-83e9-f39b9517d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "############# Setear segun cada maquina ############\n",
    "#os.chdir(\"C:/Users/herna/labo3_empresa3_repo/datasets\")\n",
    "os.chdir(\"C:/diego_tools/labo3/dataset\")\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2dd467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File in: emp3_sellout_lags_deltalags_product_categorias_sin_norm.csv\n",
      "File out: emp3_sellout_base_period_product_FE_sin_norm.csv\n"
     ]
    }
   ],
   "source": [
    "#selecciono que archivo procesar segun el tipo de transformacion a tilizar\n",
    "#//sin_norm=sin normalizacion //cero_uno=min max (0-1) //media_sd=standard media y desvio\n",
    "tipos_norm = ['sin_norm', 'cero_uno', 'media_sd']\n",
    "\n",
    "normalizacion = tipos_norm[0] \n",
    "\n",
    "#data = \"emp3_sellout_base_period_product.csv\"\n",
    "data_entrada = \"emp3_sellout_lags_deltalags_product_categorias\" #FE que dejo el NB de EMi BASE\n",
    "data_salida = \"emp3_sellout_base_period_product_FE\"\n",
    "\n",
    "if normalizacion == tipos_norm[0]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n",
    "    \n",
    "elif normalizacion == tipos_norm[1]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n",
    "    \n",
    "elif normalizacion == tipos_norm[2]:\n",
    "    data_entrada = data_entrada+\"_\"+normalizacion+\".csv\"\n",
    "    data_salida = data_salida+\"_\"+normalizacion+\".csv\"\n",
    "    print('File in: '+data_entrada)\n",
    "    print('File out: '+data_salida)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb6bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30825 entries, 0 to 30824\n",
      "Data columns (total 51 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   product_id                 30825 non-null  int64  \n",
      " 1   imputado                   30825 non-null  int64  \n",
      " 2   tn                         30825 non-null  float64\n",
      " 3   cust_request_tn            30825 non-null  float64\n",
      " 4   cust_request_qty           30825 non-null  float64\n",
      " 5   plan_precios_cuidados      30825 non-null  float64\n",
      " 6   periodo                    30825 non-null  object \n",
      " 7   mes                        30825 non-null  int64  \n",
      " 8   cat1                       30825 non-null  object \n",
      " 9   cat2                       30825 non-null  object \n",
      " 10  cat3                       30825 non-null  object \n",
      " 11  brand                      30825 non-null  object \n",
      " 12  sku_size                   30825 non-null  float64\n",
      " 13  producto_estrella          30825 non-null  float64\n",
      " 14  temp_media                 30825 non-null  float64\n",
      " 15  temp_max_media             30825 non-null  float64\n",
      " 16  temp_min_media             30825 non-null  float64\n",
      " 17  IPC                        30825 non-null  float64\n",
      " 18  promedio_mens_dolar_venta  30825 non-null  float64\n",
      " 19  catastrofe                 30825 non-null  bool   \n",
      " 20  accion                     30825 non-null  object \n",
      " 21  dif_cust_request_tn        30825 non-null  float64\n",
      " 22  dif_cust_request_tn_porc   30825 non-null  float64\n",
      " 23  tn_lag_1                   29592 non-null  float64\n",
      " 24  tn_lag_2                   28359 non-null  float64\n",
      " 25  tn_lag_3                   27126 non-null  float64\n",
      " 26  tn_mas_2                   30825 non-null  float64\n",
      " 27  tn_delta_1                 29592 non-null  float64\n",
      " 28  tn_delta_2                 28359 non-null  float64\n",
      " 29  tn_delta_3                 27126 non-null  float64\n",
      " 30  cat1_tn                    30825 non-null  float64\n",
      " 31  cat1_tn_lag_1              29592 non-null  float64\n",
      " 32  cat1_tn_delta_1            29592 non-null  float64\n",
      " 33  cat1_tn_lag_2              28359 non-null  float64\n",
      " 34  cat1_tn_delta_2            28359 non-null  float64\n",
      " 35  cat1_tn_lag_3              27126 non-null  float64\n",
      " 36  cat1_tn_delta_3            27126 non-null  float64\n",
      " 37  cat2_tn                    30825 non-null  float64\n",
      " 38  cat2_tn_lag_1              29592 non-null  float64\n",
      " 39  cat2_tn_delta_1            29592 non-null  float64\n",
      " 40  cat2_tn_lag_2              28359 non-null  float64\n",
      " 41  cat2_tn_delta_2            28359 non-null  float64\n",
      " 42  cat2_tn_lag_3              27126 non-null  float64\n",
      " 43  cat2_tn_delta_3            27126 non-null  float64\n",
      " 44  cat3_tn                    30825 non-null  float64\n",
      " 45  cat3_tn_lag_1              29592 non-null  float64\n",
      " 46  cat3_tn_delta_1            29592 non-null  float64\n",
      " 47  cat3_tn_lag_2              28359 non-null  float64\n",
      " 48  cat3_tn_delta_2            28359 non-null  float64\n",
      " 49  cat3_tn_lag_3              27126 non-null  float64\n",
      " 50  cat3_tn_delta_3            27126 non-null  float64\n",
      "dtypes: bool(1), float64(41), int64(3), object(6)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Lea el Dataset base\n",
    "df = pd.read_csv(data_entrada)\n",
    "\n",
    "columnas_a_eliminar = ['periodo']\n",
    "df = df.drop(columnas_a_eliminar, axis=1)\n",
    "df = df.rename(columns={'periodo_fecha': 'periodo'})\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeba781",
   "metadata": {},
   "source": [
    "**setting the parametros generales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75171d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#periods_to_train = ['2019-10-01','2019-09-01','2019-08-01','2019-07-01','2019-06-01','2019-05-01','2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01' ]\n",
    "#periods_to_train = ['2019-10-01']\n",
    "#de Abril 2019 y 13 meses hacia atras\n",
    "periods_to_train = ['2019-04-01','2019-03-01','2019-02-01','2019-01-01','2018-12-01','2018-11-01','2018-10-01','2018-09-01','2018-08-01','2018-07-01','2018-06-01','2018-05-01','2018-04-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a32a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando periodo: 2019-04-01\n",
      "Fecha ini lags: 2018-03-01\n",
      "Fecha fin lags: 2019-04-01\n",
      "mean from: 2019-03-01\n",
      "mean to -2 2019-02-01\n",
      "mean to -3 2019-01-01\n",
      "mean to -6 2018-10-01\n",
      "mean to -12 2018-04-01\n",
      "q from: 2019-03-01\n",
      "q to: 2019-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "Procesando periodo: 2019-03-01\n",
      "Fecha ini lags: 2018-02-01\n",
      "Fecha fin lags: 2019-03-01\n",
      "mean from: 2019-02-01\n",
      "mean to -2 2019-01-01\n",
      "mean to -3 2018-12-01\n",
      "mean to -6 2018-09-01\n",
      "mean to -12 2018-03-01\n",
      "q from: 2019-02-01\n",
      "q to: 2018-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "Procesando periodo: 2019-02-01\n",
      "Fecha ini lags: 2018-01-01\n",
      "Fecha fin lags: 2019-02-01\n",
      "mean from: 2019-01-01\n",
      "mean to -2 2018-12-01\n",
      "mean to -3 2018-11-01\n",
      "mean to -6 2018-08-01\n",
      "mean to -12 2018-02-01\n",
      "q from: 2019-01-01\n",
      "q to: 2018-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "Procesando periodo: 2019-01-01\n",
      "Fecha ini lags: 2017-12-01\n",
      "Fecha fin lags: 2019-01-01\n",
      "mean from: 2018-12-01\n",
      "mean to -2 2018-11-01\n",
      "mean to -3 2018-10-01\n",
      "mean to -6 2018-07-01\n",
      "mean to -12 2018-01-01\n",
      "q from: 2018-12-01\n",
      "q to: 2018-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "Procesando periodo: 2018-12-01\n",
      "Fecha ini lags: 2017-11-01\n",
      "Fecha fin lags: 2018-12-01\n",
      "mean from: 2018-11-01\n",
      "mean to -2 2018-10-01\n",
      "mean to -3 2018-09-01\n",
      "mean to -6 2018-06-01\n",
      "mean to -12 2017-12-01\n",
      "q from: 2018-11-01\n",
      "q to: 2018-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "Procesando periodo: 2018-11-01\n",
      "Fecha ini lags: 2017-10-01\n",
      "Fecha fin lags: 2018-11-01\n",
      "mean from: 2018-10-01\n",
      "mean to -2 2018-09-01\n",
      "mean to -3 2018-08-01\n",
      "mean to -6 2018-05-01\n",
      "mean to -12 2017-11-01\n",
      "q from: 2018-10-01\n",
      "q to: 2018-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "Procesando periodo: 2018-10-01\n",
      "Fecha ini lags: 2017-09-01\n",
      "Fecha fin lags: 2018-10-01\n",
      "mean from: 2018-09-01\n",
      "mean to -2 2018-08-01\n",
      "mean to -3 2018-07-01\n",
      "mean to -6 2018-04-01\n",
      "mean to -12 2017-10-01\n",
      "q from: 2018-09-01\n",
      "q to: 2018-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "Procesando periodo: 2018-09-01\n",
      "Fecha ini lags: 2017-08-01\n",
      "Fecha fin lags: 2018-09-01\n",
      "mean from: 2018-08-01\n",
      "mean to -2 2018-07-01\n",
      "mean to -3 2018-06-01\n",
      "mean to -6 2018-03-01\n",
      "mean to -12 2017-09-01\n",
      "q from: 2018-08-01\n",
      "q to: 2018-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "Procesando periodo: 2018-08-01\n",
      "Fecha ini lags: 2017-07-01\n",
      "Fecha fin lags: 2018-08-01\n",
      "mean from: 2018-07-01\n",
      "mean to -2 2018-06-01\n",
      "mean to -3 2018-05-01\n",
      "mean to -6 2018-02-01\n",
      "mean to -12 2017-08-01\n",
      "q from: 2018-07-01\n",
      "q to: 2018-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "Procesando periodo: 2018-07-01\n",
      "Fecha ini lags: 2017-06-01\n",
      "Fecha fin lags: 2018-07-01\n",
      "mean from: 2018-06-01\n",
      "mean to -2 2018-05-01\n",
      "mean to -3 2018-04-01\n",
      "mean to -6 2018-01-01\n",
      "mean to -12 2017-07-01\n",
      "q from: 2018-06-01\n",
      "q to: 2018-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "Procesando periodo: 2018-06-01\n",
      "Fecha ini lags: 2017-05-01\n",
      "Fecha fin lags: 2018-06-01\n",
      "mean from: 2018-05-01\n",
      "mean to -2 2018-04-01\n",
      "mean to -3 2018-03-01\n",
      "mean to -6 2017-12-01\n",
      "mean to -12 2017-06-01\n",
      "q from: 2018-05-01\n",
      "q to: 2018-03-01\n",
      "q from: 2018-02-01\n",
      "q to: 2017-12-01\n",
      "q from: 2017-11-01\n",
      "q to: 2017-09-01\n",
      "q from: 2017-08-01\n",
      "q to: 2017-06-01\n",
      "Procesando periodo: 2018-05-01\n",
      "Fecha ini lags: 2017-04-01\n",
      "Fecha fin lags: 2018-05-01\n",
      "mean from: 2018-04-01\n",
      "mean to -2 2018-03-01\n",
      "mean to -3 2018-02-01\n",
      "mean to -6 2017-11-01\n",
      "mean to -12 2017-05-01\n",
      "q from: 2018-04-01\n",
      "q to: 2018-02-01\n",
      "q from: 2018-01-01\n",
      "q to: 2017-11-01\n",
      "q from: 2017-10-01\n",
      "q to: 2017-08-01\n",
      "q from: 2017-07-01\n",
      "q to: 2017-05-01\n",
      "Procesando periodo: 2018-04-01\n",
      "Fecha ini lags: 2017-03-01\n",
      "Fecha fin lags: 2018-04-01\n",
      "mean from: 2018-03-01\n",
      "mean to -2 2018-02-01\n",
      "mean to -3 2018-01-01\n",
      "mean to -6 2017-10-01\n",
      "mean to -12 2017-04-01\n",
      "q from: 2018-03-01\n",
      "q to: 2018-01-01\n",
      "q from: 2017-12-01\n",
      "q to: 2017-10-01\n",
      "q from: 2017-09-01\n",
      "q to: 2017-07-01\n",
      "q from: 2017-06-01\n",
      "q to: 2017-04-01\n"
     ]
    }
   ],
   "source": [
    "first_df = True\n",
    "i = 1\n",
    "for periodo in periods_to_train:\n",
    "    \n",
    "    #cada periodo\n",
    "    print(\"Procesando periodo:\", periodo)\n",
    "    \n",
    "    #tomo periodo para generar mi dataset de train\n",
    "    df_train = df[df['periodo'] == periodo]\n",
    "    \n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag tn\n",
    "    #========================================================================================\n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-13)  # Suma 2 meses a la fecha\n",
    "    fecha_inicio = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha ini lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    fecha = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha += relativedelta(months=-0)  # Suma 2 meses a la fecha\n",
    "    fecha_fin = fecha.strftime('%Y-%m-%d')\n",
    "    print(\"Fecha fin lags:\", fecha.strftime('%Y-%m-%d'))\n",
    "    fecha_inicio = pd.Timestamp(fecha_inicio)\n",
    "    fecha_fin = pd.Timestamp(fecha_fin)\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        #print('entro')\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        # Seleccionar solo las columnas 'product_id' y 'tn', y renombrar 'tn' como 'lag_tn_xx'\n",
    "        df_nuevo = df_filtrado[['product_id', 'tn']].rename(columns={'tn': 'lag_tn_'+str(lag)})\n",
    "\n",
    "\n",
    "        df_train = pd.merge(df_train, df_nuevo, on='product_id', how='left')\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #tomo rango de fechas para 13 lags campo lag months\n",
    "    #========================================================================================\n",
    "\n",
    "    lag = 13\n",
    "    # Iterar a través de los periodos en el rango\n",
    "    for fecha in pd.date_range(start=fecha_inicio, end=fecha_fin, freq='M'):\n",
    "        # Obtiene el primer día del mes para cada fecha\n",
    "        fecha = pd.to_datetime(fecha)\n",
    "        primer_dia_del_mes = fecha - pd.DateOffset(days=fecha.day - 1)\n",
    "        primer_dia_del_mes = primer_dia_del_mes.strftime('%Y-%m-%d')\n",
    "        #print(primer_dia_del_mes)\n",
    "        # Filtrar el DataFrame por el periodo actual\n",
    "        filtro = df['periodo'] == primer_dia_del_mes\n",
    "        df_filtrado = df[filtro]\n",
    "        #print(str(fecha.month))\n",
    "        df_train['lag_month_'+str(lag)] = str(fecha.month)\n",
    "        lag = lag - 1\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_mean_2_3_6_12 \n",
    "    #========================================================================================\n",
    "    mean_periods = [-2,-3,-6,-12]\n",
    "    fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "    fecha_from += relativedelta(months=-1)  # Suma 2 meses a la fecha\n",
    "    fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "    print(\"mean from:\", fecha_from)\n",
    "    \n",
    "    for mean_period in mean_periods:\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=mean_period)  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"mean to \"+str(mean_period) , fecha_to)\n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        df_filtrado = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado = df_filtrado.rename(columns={'tn': 'lag_tn_mean_'+str(abs(mean_period))})\n",
    "        df_train = pd.merge(df_train, df_filtrado, on='product_id', how='left')\n",
    "\n",
    "    #========================================================================================\n",
    "    #genero el campo lag_tn_sum_q1_q2_q3_q4 y lag_tn_mean_q1_q2_q3_q4\n",
    "    #========================================================================================\n",
    "    quarters = [[-1,-3], [-4,-6], [-7,-9], [-10,-12]]\n",
    "    quarters_name = ['q1', 'q2', 'q3', 'q4']\n",
    "    \n",
    "    for i in range(len(quarters)):\n",
    "        \n",
    "        fecha_from = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_from += relativedelta(months=quarters[i][0])  # Suma 2 meses a la fecha\n",
    "        fecha_from = fecha_from.strftime('%Y-%m-%d')\n",
    "        print(\"q from:\", fecha_from)\n",
    "\n",
    "        fecha_to = datetime.strptime(periodo, '%Y-%m-%d')  # Convierte la cadena a objeto datetime\n",
    "        fecha_to += relativedelta(months=quarters[i][1])  # Suma 2 meses a la fecha\n",
    "        fecha_to = fecha_to.strftime('%Y-%m-%d')\n",
    "        print(\"q to:\", fecha_to)\n",
    "        \n",
    "        filtro = (df['periodo'] >= fecha_to) & (df['periodo'] <= fecha_from)\n",
    "        df_filtrado = df[filtro]\n",
    "        #para sum\n",
    "        df_filtrado_sum = df_filtrado.groupby(['product_id']).agg({'tn': 'sum'}).reset_index()\n",
    "        df_filtrado_sum = df_filtrado_sum.rename(columns={'tn': 'lag_sum_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_sum, on='product_id', how='left')\n",
    "        #para mean\n",
    "        df_filtrado_mean = df_filtrado.groupby(['product_id']).agg({'tn': 'mean'}).reset_index()\n",
    "        df_filtrado_mean = df_filtrado_mean.rename(columns={'tn': 'lag_mean_tn_'+quarters_name[i]})\n",
    "        df_train = pd.merge(df_train, df_filtrado_mean, on='product_id', how='left')    \n",
    "\n",
    "        \n",
    "    if first_df:\n",
    "        first_df = False\n",
    "        df_train_final = df_train\n",
    "    else:\n",
    "        df_train_final = pd.concat([df_train_final, df_train], axis=0, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a87c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Trend by quarters\n"
     ]
    }
   ],
   "source": [
    "#========================================================================================\n",
    "#genero el campo lag_trend_q1 q2 q3 q4\n",
    "#========================================================================================\n",
    "\n",
    "def calculate_trend(row, *lag_column_names):\n",
    "    # Filtrar valores no nulos para el cálculo de tendencia\n",
    "    lag_values = [row[col] for col in lag_column_names if not np.isnan(row[col])]\n",
    "\n",
    "    # Verificar que haya suficiente variación en los datos para un ajuste lineal\n",
    "    if len(set(lag_values)) > 1:\n",
    "        coefficients = np.polyfit([1, 2, 3], lag_values, 1)\n",
    "        return coefficients[0]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "print(\"Columns Trend by quarters\")\n",
    "#Q1\n",
    "column_names = [\"lag_tn_1\", \"lag_tn_2\", \"lag_tn_3\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q1\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q2\n",
    "column_names = [\"lag_tn_4\", \"lag_tn_5\", \"lag_tn_6\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q2\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q3\n",
    "column_names = [\"lag_tn_7\", \"lag_tn_8\", \"lag_tn_9\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q3\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()\n",
    "#Q4\n",
    "column_names = [\"lag_tn_10\", \"lag_tn_11\", \"lag_tn_12\"]\n",
    "df_train_final[column_names] = df_train_final[column_names].fillna(0)\n",
    "df_train_final[\"lag_trend_q4\"] = df_train_final.apply(calculate_trend, args=column_names, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3390ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mover la columna 'tn_mas_2' target al último lugar\n",
    "col_T = df_train_final.pop('tn_mas_2')\n",
    "df_train_final['tn_mas_2'] = col_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10199e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imputado</th>\n",
       "      <th>tn</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>periodo</th>\n",
       "      <th>mes</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_sum_tn_q3</th>\n",
       "      <th>lag_mean_tn_q3</th>\n",
       "      <th>lag_sum_tn_q4</th>\n",
       "      <th>product_id</th>\n",
       "      <th>lag_mean_tn_q4</th>\n",
       "      <th>lag_trend_q1</th>\n",
       "      <th>lag_trend_q2</th>\n",
       "      <th>lag_trend_q3</th>\n",
       "      <th>lag_trend_q4</th>\n",
       "      <th>tn_mas_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1259.09363</td>\n",
       "      <td>1343.99435</td>\n",
       "      <td>367.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>...</td>\n",
       "      <td>3915.09966</td>\n",
       "      <td>1305.033220</td>\n",
       "      <td>4151.88466</td>\n",
       "      <td>20001</td>\n",
       "      <td>1383.961553</td>\n",
       "      <td>906.507555</td>\n",
       "      <td>-247.118320</td>\n",
       "      <td>-88.256105</td>\n",
       "      <td>-103.759960</td>\n",
       "      <td>1647.63848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1043.01349</td>\n",
       "      <td>1090.26594</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>...</td>\n",
       "      <td>3114.62275</td>\n",
       "      <td>1038.207583</td>\n",
       "      <td>2678.07065</td>\n",
       "      <td>20002</td>\n",
       "      <td>892.690217</td>\n",
       "      <td>883.405340</td>\n",
       "      <td>-108.303010</td>\n",
       "      <td>62.994760</td>\n",
       "      <td>-143.604235</td>\n",
       "      <td>1287.62346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>366.72969</td>\n",
       "      <td>373.84550</td>\n",
       "      <td>366.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>...</td>\n",
       "      <td>1174.89383</td>\n",
       "      <td>391.631277</td>\n",
       "      <td>1181.15006</td>\n",
       "      <td>20009</td>\n",
       "      <td>393.716687</td>\n",
       "      <td>275.981270</td>\n",
       "      <td>-33.683675</td>\n",
       "      <td>4.361500</td>\n",
       "      <td>68.296225</td>\n",
       "      <td>391.28033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>424.16407</td>\n",
       "      <td>433.77594</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>...</td>\n",
       "      <td>993.45547</td>\n",
       "      <td>331.151823</td>\n",
       "      <td>1222.99770</td>\n",
       "      <td>20015</td>\n",
       "      <td>407.665900</td>\n",
       "      <td>223.968275</td>\n",
       "      <td>-75.928095</td>\n",
       "      <td>27.381440</td>\n",
       "      <td>75.955830</td>\n",
       "      <td>315.31224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>263.67957</td>\n",
       "      <td>264.82235</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.82771</td>\n",
       "      <td>342.275903</td>\n",
       "      <td>718.42769</td>\n",
       "      <td>20026</td>\n",
       "      <td>239.475897</td>\n",
       "      <td>153.557170</td>\n",
       "      <td>12.298425</td>\n",
       "      <td>23.605795</td>\n",
       "      <td>-60.027475</td>\n",
       "      <td>215.64691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   imputado          tn  cust_request_tn  cust_request_qty  \\\n",
       "0         0  1259.09363       1343.99435             367.0   \n",
       "1         0  1043.01349       1090.26594             377.0   \n",
       "2         0   366.72969        373.84550             366.0   \n",
       "3         0   424.16407        433.77594             319.0   \n",
       "4         0   263.67957        264.82235             360.0   \n",
       "\n",
       "   plan_precios_cuidados     periodo  mes cat1         cat2     cat3  ...  \\\n",
       "0                    0.0  2019-02-01    2   HC  ROPA LAVADO  Liquido  ...   \n",
       "1                    0.0  2019-02-01    2   HC  ROPA LAVADO  Liquido  ...   \n",
       "2                    0.0  2019-02-01    2   HC  ROPA LAVADO  Liquido  ...   \n",
       "3                    0.0  2019-02-01    2   HC  ROPA LAVADO  Liquido  ...   \n",
       "4                    0.0  2019-02-01    2   HC  ROPA LAVADO  Liquido  ...   \n",
       "\n",
       "  lag_sum_tn_q3  lag_mean_tn_q3  lag_sum_tn_q4  product_id  lag_mean_tn_q4  \\\n",
       "0    3915.09966     1305.033220     4151.88466       20001     1383.961553   \n",
       "1    3114.62275     1038.207583     2678.07065       20002      892.690217   \n",
       "2    1174.89383      391.631277     1181.15006       20009      393.716687   \n",
       "3     993.45547      331.151823     1222.99770       20015      407.665900   \n",
       "4    1026.82771      342.275903      718.42769       20026      239.475897   \n",
       "\n",
       "   lag_trend_q1  lag_trend_q2  lag_trend_q3  lag_trend_q4    tn_mas_2  \n",
       "0    906.507555   -247.118320    -88.256105   -103.759960  1647.63848  \n",
       "1    883.405340   -108.303010     62.994760   -143.604235  1287.62346  \n",
       "2    275.981270    -33.683675      4.361500     68.296225   391.28033  \n",
       "3    223.968275    -75.928095     27.381440     75.955830   315.31224  \n",
       "4    153.557170     12.298425     23.605795    -60.027475   215.64691  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a81221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "df_train_final.to_csv(data_salida, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
